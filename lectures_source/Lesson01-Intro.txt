// notes_to_pdf.py --input lectures_source/Lesson1-Intro.txt --output tmp.pdf --type slides --skip_action cleanup_after --debug_on_error --toc_type navigation

::: columns
:::: {.column width=15%}
![](lectures_source/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{Introduction}}$$**
\endgroup

::: columns
:::: {.column width=75%}
\vspace{1cm}

**Instructor**: Dr. GP Saggese - `gsaggese@umd.edu`

**References**:

- AIMA Chap 1
::::
:::: {.column width=20%}

![](lectures_source/covers/Lesson01-Intro.png){width=70%}
::::
:::

# ##############################################################################
# A Map of Machine Learning
# ##############################################################################

* A Map of Machine Learning

```mermaid
mindmap
  root((**Machine Learning**))
    (**Paradigms**)
      Supervised
      Unsupervised
      RL
      Active
      Online
    (**Theory**)
      VC theory
      Bias-variance decomposition
      MDL
      Bayesian
    (**Models**)
      Linear
      GLM
      Neural networks
      KNN
      SVM
      Graphical models
    (**Techniques**)
      Pre-processing
      Model building
      Performance evaluation
      Regularization
      Ensemble learning
```

* Machine Learning Theory
- **VC theory**
  - Measure model capacity and generalize based on hypothesis space complexity

- **Bias-variance decomposition**
  - Prediction error is the sum of:
    - Bias: Error from simplistic model assumptions
    - Variance: Error due to sensitivity to training data fluctuations

- **Computation complexity**
  - Related to information theory and compression
  - E.g., Minimum Description Length (MDL) measures model complexity via
    efficient model and data description

- **Bayesian approach**
  - Treat ML as probability
  - Combine prior knowledge with observed data to update belief about a model

- **Problem in ML theory**
  - Assumptions may not align with practical problems

* Machine Learning Paradigms
- How do you set up the learning problem?

  - **Supervised learning**
    - The dataset includes inputs with corresponding outputs
    - Develop an input-output relationship

  - **Unsupervised learning**
    - The data is unlabeled, discover structure within the data
    - E.g., anomaly detection, clustering

  - **Reinforcement learning**
    - The correct answer is not immediately available
    - Evaluate actions based on final outcomes

  - **Active learning**
    - Not all examples are available initially
    - Request outputs for specific inputs

  - ...

* Machine Learning Models
- What is the form of the model and how to fit / predict from the data?

  - Linear models

  - Generalized linear models
    - E.g., logistic, Poisson regression

  - Support Vector Machines (SVM)

  - Nearest neighbors
    - E.g., k-means clustering, KNN

  - Gaussian processes

  - Graphical models
    - Model joint distributions with graphs
    - E.g., hidden Markov models (HMM), Kalman filters, Bayesian networks

  - Neural networks

  - ...

* Machine Learning Techniques
- What are the stages of a ML pipeline?

  - **Input processing**
    - Data cleaning
    - Dimensionality reduction
    - Feature engineering

  - **Model building**
    - Models
    - Learning algorithms

  - **Performance evaluation**
    - Cross-validation
    - Bias-variance curves
    - Learning curves

  - **Regularization**

  - **Aggregation**
    - Boosting
    - Bagging
    - Stacking

# ##############################################################################
# What Is Artificial Intelligence
# ##############################################################################

## #############################################################################
## AI
## #############################################################################

* Human Intelligence
- We call ourselves "homo sapiens" because intelligence sets us apart from animals

- For thousands of years, we tried to understand how we think
  - Brain is a small mass of matter
  - How can brain perceive, understand, predict, and manipulate a world more
    complicated than itself?

* Artificial Intelligence
- The term "Artificial Intelligence" was coined in 1956

- **AI aims to:**
  - Understand human intelligence
  - Create intelligent entities

- **AI is a technology**
  - Universal and applicable to any human activity and task
  - Its impact greater than any previous historical event
  - Currently generates trillions of dollars annually in revenue
  - Presents many unresolved problems
    - E.g., major concepts in physics might be established

* AI Formal Definition
- AI is defined around **two axes**:
  - Thinking vs. Acting
  - Human vs. Rational (ideal performance)

- This leads to four possible definitions of AI as a machine that can:
  1. Think humanly
  2. Think rationally
  3. Act humanly
  4. Act rationally

* AI Formal Definition: Quiz
- Four possible definitions of AI as a machine that can:
  1. Think humanly
  2. Think rationally
  3. Act humanly
  4. Act rationally

- **Which one do you think is the best definition?**

* AI Formal Definition: Quiz
- Four possible definitions of AI as a machine that can:
  1. Think humanly
  2. Think rationally
  3. Act humanly
  4. Act rationally

- **Which one do you think is the best definition?**

- We will see that building machines that can **"act rationally"** should be
  ultimate goal of AI

* 1. AI as Thinking Humanly
- To build machines that think like humans we need to **determine how humans
  think**

- **Pros**
  - Express precise theory of the human mind as a computer program

- **Cons**
  - Unknown workings of the human mind
  - Anthropocentric definition

* 2. AI as Thinking Rationally
- What are the rules of "correct thinking"?
  - Given correct premises, yield correct conclusions

- **Logic** studies the "laws of thought"
  - Formalize statements about objects and their relations

- **Automatic theorem proving**
  - Programs solve problems in logical notation
  - Run indefinitely if no solution exists (related to the halting problem)

* Thinking Rationally: Cons

1. **Formalizing informal knowledge is difficult**
   - Example: _"A handshake occurs when two people extend, grip, shake hands,
     then release."_
   - Formal logic representation: 
     \begin{align*}
         &\exists x, y \, ( \text{Person}(x) \land \text{Person}(y) \land x \neq y \land \\
         &\quad \text{Hand}(x, h_x) \land \text{Hand}(y, h_y) \land \\
         &\quad \text{MoveToward}(h_x, h_y) \land \text{Contact}(h_x, h_y) \land \\
         &\quad \text{Shake}(h_x, h_y) \land \\
         &\quad \text{Release}(h_x, h_y) )
     \end{align*}
2. **Probabilistic nature of knowledge**
   - Example in medicine: _"Fever, cough, and fatigue could indicate flu,
     COVID-19, or another illness."_
3. **Scalability challenges**
   - Large problems may need heuristics for practical solutions
4. **Intelligence requires more than rational thinking**
   - Importance of agent interaction with the world
   - Problem of the "body"

* 3. AI as Acting Humanly
- **Agent** is something that perceives and acts to reach a goal
  - AI designs agent that can act like humans

- **(Embodied) Turing test**
  - _"A computer passes the Turing test if a human cannot tell whether the
    answers to questions came from a person or a computer"_
  - Passing the Turing test requires:
    1. Natural language processing to communicate in English
    2. Knowledge representation to store what it knows
    3. Automated reasoning to use stored knowledge to answer questions
    4. Machine learning to detect and extrapolate patterns
    5. Computer vision and speech recognition to perceive objects and understand
       human talking to them
    6. Robotics to manipulate objects and move around

* Turing Test: Pros and Cons

- **Pros**
  - Operational definition of intelligence
  - Sidestep philosophical vagueness of "What is consciousness? Can a machine
    think? ..."

- **Cons**
  - Anthropomorphic criteria define intelligence in human terms
    - Multiple forms of non-human intelligence exist
  - Intelligence in terms of Turing test
    - Design intelligence to imitate humans
    - Fool humans into thinking it's human
  - E.g., aeronautical engineering:
    - Focus on wind tunnels and aerodynamics
    - Not about designing machines that imitate birds
    - Not about fooling birds into thinking it's a bird

* 4. AI as Acting Rationally
- Rational agents $\iff$ do the "right thing" given what they know

- Computer agents that act rationally should:
  1. Operate autonomously
  2. Perceive environment
  3. Persist over a prolonged time period
  4. Adapt to change
  5. Create and pursue goals

* Acting Rationally as Ultimate Goal of AI
- Which definition of AI to use?
  - Acting vs. Thinking
  - Rational vs. Human

- **Acting > Thinking**
  - Acting rationally is broader than just thinking rationally

- **Rational > Human**
  - Rationality can be mathematically defined
  - Human behavior is shaped by evolutionary conditions

- AI focuses on **agents acting rationally**
  - I.e., "agents that do the right thing" based on available knowledge
  - E.g., you leave the house and a branch strikes you
    - Did you act rationally?
    - Probably
  - E.g., you cross the street and a car knocks you over
    - Did you act rationally?
    - Id depends!

* Goals of a Rational Agent
- A **rational agent** aims for:
  - The best outcome in a deterministic setup
  - The best expected outcome under uncertainty

- **Best** is determined by the objective function:
  - E.g., cost function, sum of rewards, loss function, utility

- **Problems** with acting rationally
  - Sometimes no provably correct action exists
    - Yet, an action must be taken
  - Perfect rationality is not always feasible due to:
    - Cost of acquiring all data
    - Computational demands
  - Acting "appropriately", "satisficing"

## #############################################################################
## Machine Learning
## #############################################################################

* Machine Learning: Definitions
- Artificial intelligence differs from human intelligence
  - Machines don't learn like humans (e.g., LLMs)

- _"Machine learning is the field of study that gives computers the ability to
  learn without being explicitly programmed"_, (Arthur Samuel, 1959)
- _"A computer program is said to learn from experience $E$ with respect to some
  task $T$ and some performance measure $P$, if $P(T)$ improves with experience
  $E$"_, (Tom Mitchell, 1998)

- Machine learning is the science of building machines capable of doing useful
  things without being explicitly programmed to do so
  - E.g. a computer learn to play checkers by playing against itself, memorizing
    which positions lead to winning a game

* Limits of ML Compared to Human Intelligence

- **Fragility to input variations**
  - ML models fail with slight input distortions
    - E.g., adversarial attacks cause misclassification by altering one pixel
    - E.g., a model trained for a video game may fail if the screen is slightly
      rotated; humans continue effortlessly

- **Lack of transfer learning**
  - ML systems cannot apply knowledge across domains without retraining

- **Massive data and compute requirements**
  - ML requires enormous datasets and computational resources
    - E.g., a teenager learns to drive in hours; self-driving systems need
      billions of compute hours and extensive data

- **Poor common sense and reasoning**
  - ML lacks built-in world knowledge and intuitive logic

* Limits of ML Compared to Human Intelligence

- **Opaque decision-making**
  - Many ML models offer little transparency into decision processes
    - Limits trust, interpretability, and accountability in critical
      applications

- **Dependence on narrow objectives**
  - ML systems excel at optimizing narrow tasks but fail with ambiguous goals
    - E.g., an algorithm maximizing user engagement may promote harmful
      content

- **Susceptibility to bias and data quality**
  - Models inherit and amplify biases in training data

- **Lack of embodiment and physical interaction**
  - Human cognition is grounded in physical and sensory experience

* The 3 Machine Learning Assumptions
- Machine learning involves solving a practical problem by:
  - Gathering a dataset
  - Building a statistical model from the dataset algorithmically

- The **three assumptions** of machine learning
  - A pattern exists
  - Pattern cannot be precisely defined mathematically
  - Data is available

- Which ML assumption is essential?
  - _A pattern exists_
    - If no pattern, try learning, measure effectiveness, conclude it doesn't
      work
  - _Cannot pin down pattern mathematically_
    - If solution is direct, ML not recommended, but may still apply
  - _We have data_
    - Without data, no progress can be made
    - Data is crucial

* Machine Learning Adages

- _"An explanation of the data should be as simple as possible, but not
  simpler"_ (Einstein)

- _"The simplest model that fits the data is also the most plausible"_ (Occam's
  razor)

- _"Garbage in, garbage out"_ (Fuechse, 1957)

- _"All models are wrong, but some are useful"_ (George E. P. Box, 1976)

- _"If you torture the data long enough it will confess whatever you want"_
  (Coase, 1982)

- _"Data is the new oil"_ (Humby, 2006)

- _"More data beats clever algorithms"_ (Norvig, ~2006)

- _"The unreasonable effectiveness of data"_ (Halevy, Norvig, Pereira, 2009)

## #############################################################################
## AI vs ML vs Deep-Learning
## #############################################################################

* AI vs ML vs Deep-Learning
::: columns
:::: {.column width=65%}
- **AI**: Machines programmed to reason, learn, and act in a rational way

- **ML**: Machines capable of performing tasks without being explicitly programmed,
  e.g.,
  - Natural language processing
  - Computer vision
  - Speech recognition

- **AI without ML**:
  - Example: Rule-based systems (e.g., IBM Deep Blue playing chess)

- **Deep Learning (DL)**: ML using neural networks with multiple layers
  - Example: Autonomous vehicles

- **Large Language Models (LLM)**: neural networks trained on massive text
  datasets and RLHS

::::
:::: {.column width=30%}

```tikz
  % Define colors (optional)
  \definecolor{AIcolor}{RGB}{200, 200, 255}
  \definecolor{MLcolor}{RGB}{200, 255, 200}
  \definecolor{DLcolor}{RGB}{255, 200, 200}
  \definecolor{LLMcolor}{RGB}{255, 255, 150}

  % Draw AI circle
  \fill[AIcolor] (0,0) circle (3);
  \draw (0,0) circle (3);
  \node[above] at (0,2) {\textbf{AI}};

  % Draw ML circle inside AI
  \fill[MLcolor] (0.5,-0.5) circle (2);
  \draw (0.5,-0.5) circle (2);
  \node[above] at (0.5,0.5) {\textbf{ML}};

  % Draw DL circle inside ML
  \fill[DLcolor] (1,-1) circle (1);
  \draw (1,-1) circle (1);
  \node[above] at (1,-0.6) {\textbf{DL}};

  % Draw LLM circle inside DL
  \fill[LLMcolor] (1.2,-1.2) circle (0.6);
  \draw (1.2,-1.2) circle (0.6);
  \node[above] at (1.2,-1.4) {\textbf{LLMs}};
```
::::
:::

## #############################################################################
## The Foundation of AI
## #############################################################################

* AI Relates to Many Other Disciplines

```mermaid
mindmap
  root((AI))
    Philosophy
    Mathematics
    Economics
    Neuroscience
    Psychology
    Computer engineering
    Control theory
    Linguistics
```

* AI and Philosophy (1/2)

- **Can formal rules be used to draw valid conclusions?**

  - Reasoning
    - Aristotle (400 BCE) formulated laws governing the rational mind
    - Machines were built for arithmetic operations (e.g., Pascaline, 1600)
    - Logic studies rules of proper reasoning

  - Rationalism
    - Use reasoning to understand the world

- **How does the mind arise from a physical brain?**

  - Dualism
    - Nature follows physical laws
    - Part of the human mind ("the soul") is exempt from physical laws

  - Materialism
    - The mind is a physical system, following the laws of physics
    - Where is free will? Free will is the perception of available choices

* AI and Philosophy (2/2)

- **What does knowledge come from?**

  - Empiricism
    - Knowledge via senses
    - Example: learn that trees are green by looking at them

  - Induction
    - General rules from associations
    - Example: seeing many swans are white, inferring all swans are white

  - Logical Positivism
    - Knowledge as logical theories linked to sensory observations
    - Example: scientific hypotheses connected to experimental data

- **How does knowledge lead to action?**

  - Utilitarianism
    - Measures "utility" linking knowledge to action
    - Actions justified by logic connecting goals and outcomes

  - Consequentialism
    - Right or wrong determined by action's expected outcomes
    - E.g., "If you kill, you will go to jail"

  - Deontological ethics
    - Opposes consequentialism
    - "Right actions" based on universal laws, not outcomes
    - E.g., "don't kill", "don't lie"

* AI and Cognitive Psychology

- **How do humans think and act?**

  - Cognitive Psychology
    - Brain as an information-processing device
    - Stimuli translated into internal representation
    - Representation manipulated by cognitive processes to derive new internal
      representations ("beliefs")
    - Representations turned into actions ("goals")

  - Cognitive Science
    - Use computer models to address memory, language, and logic thinking

  - Human-Computer Interaction (HCI)
    - From artificial intelligence (AI) to intelligence augmentation (IA)
    - Computers augment human abilities

* AI and Mathematics

- **What are the formal rules to draw valid conclusions?**

  - Formal Logic
    - Logical deduction rules (Boole, 1850)
    - First-order logic includes objects and relations (Frege, 1879)

  - Limits to Deduction
    - Some statements are "undecidable"
    - Incompleteness theorem: true statements exist that cannot be proved in any
      formal theory (Godel, 1931)

- **How do we reason with uncertain information?**

  - Probability
    - Mathematics of uncertainty
    - Key contributors: Cardano, Pascal, Bernoulli, Bayes (1500-1700)

  - Statistics
    - Combines data with probability
    - E.g., experiment design, data analysis, hypothesis testing, asymptotics

* AI and Economics (1/2)

- **How to make decisions to maximize payoff given preferences?**

  - Economies
    - Agents maximize economic well-being (utility)
    - Studies desires and preferences

  - Decision theory
    - Making decisions under uncertainty for preferred outcomes
    - Probability theory + utility theory
    - Examples: Investment choices, policy decisions

- ** How to make decisions when payoffs are result of several actions?**

  - Operations Research
    - Make rational decisions with payoffs for sequence of actions (Bellman, 1957)
    - E.g., Markov Decision Processes

  - Satisficing
    - Decisions that are good enough
    - Closer to human behavior
    - Example: Choosing a restaurant that meets basic criteria rather than finding
      the perfect one

* AI and Economics (2/2)

- **\red{How multiple agents with different goals act?}**

  - **Large Economies**
    - Many agents with no mutual impact
    - Ignore other agents' actions
    - E.g., national economy where individual actions don't affect market

  - **Small Economies**
    - One player's actions influence others' utility
    - E.g., local market where one seller's pricing affects competitors

  - **Game Theory**
    - Small economies resemble a "game" (Von Neumann, 1944)
    - Rational agents might need randomized strategies
    - E.g., rock-paper-scissors where randomization prevents predictability

* AI and Linguistics

- **How can you create systems that understand natural language?**

  - Computational linguistics (NLP) studies sentence structure and meaning
    - Machine translation (e.g., Google Translate)
    - Sentiment analysis in social media
    - Automated customer support chatbots

- **How does language relate to thought?**

  - Knowledge representation: how to represent knowledge for computer reasoning
  - E.g., first order knowledge, knowledge graphs

* AI and Neuroscience
- **Brain**
  - Parts handle specific cognitive functions
  - Information processing in the cerebral cortex
  - E.g., frontal lobe injury may impair decision-making

- **Anatomy of the Brain**
  - Composed of neurons (~100 billion)
    - Each neuron connects with 10-100k others via synapses
    - Axons enable long-range connections
  - Signals propagate through electrochemical reactions
  - Short-term pathways support long-term connections (learning)

- **Memory**
  - No theory yet about individual memory storage
  - Current theory: memories reconstructed

* The Brain Causes the Mind
- _Simple cells lead to thought and consciousness_
  - Truly amazing conclusion!
  - Complex processes emerge
  - Supercomputers' complexity rivals the brain
  - Achieving brain's intelligence level remains unknown

- **Brain-Machine Interface**
  - Brain adjusts to devices (e.g., learn to use prosthetics as limbs)

- **AI Singularity**
  - Future point when AI surpasses human intelligence
    - AI improves autonomously, leading to rapid growth
    - Recursive self-improvement leads to superintelligence
  - Potential societal impact
    - Control problem/value alignment: ensure AI aligns with human values
    - Economic/social disruption due to automation
  - Hard to predict

* AI and Computer Science

- **What can be computed?**
  - Algorithm
    - Procedure to solve problems
    - E.g., algorithm for computing GCD (Euclid, 300 BCE)

  - Limits to Computation
    - Turing machine (1936): Computes any computable function
    - Some functions are non-computable
    - E.g., the halting problem, i.e., decide if a program terminates

  - Tractability
    - Problem is intractable if solving time grows exponentially with size
    - Complexity classes: Polynomial vs exponential complexity (NP-problems)

* AI and Control Theory and Cybernetics

- **How can artifacts operate under their own control?**

  - Control theory
    - Study self-regulating feedback control systems
    - E.g., a water regulator that maintains a constant water flow
    - Mechanisms to minimize error between current and goal states
    - Kalman Filter (Kalman, 1960)
    - Based on calculus, matrix, stochastic optimal control
    - AI: logical inference, symbolic planning, computation

* AI and Computer Engineering

- **How can we build an efficient computer?**

  - Electronic computers
    - Built during World War II

  - Moore's Law
    - Performance doubled every 18 months (1970-2005)
    - Power and scaling issues shifted focus to multi-core over clock speed

  - Hardware for AI
    - GPUs
    - TPUs
    - Wafer-scale engines

  - Current Trends
    - Massive parallelism (like brain function)
    - Computing power doubling every 3 months
    - GPUs / TPUs used in deep learning
    - High precision (e.g., 64b) often unnecessary

  - Quantum Computing
    - Potential for significant acceleration in key computations
    - E.g., Shor's algorithm for factorization

## #############################################################################
## Brief History of AI
## #############################################################################

* AI Timeline
```raw_latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning}

\begin{document}
\begin{tikzpicture}[
  font=\sffamily,
  year/.style={font=\large\bfseries, text=blue!70!black},
  circlemark/.style={
    draw=blue!70!black, fill=white, line width=2pt, circle, minimum size=10pt
  },
  event/.style={
    align=left, text width=5.5cm, font=\large
  }
]

% Diagonal timeline
\draw[blue!70!black, thick] (0,0) -- (16,16);

% Adjusted coordinates: x and y increase together
\foreach \i/\x/\y in {
  1943/0/0, 1956/2/2, 1969/4/4, 1973/5.5/5.5, 1986/7/7, 1988/8/8,
  2001/9.5/9.5, 2011/11/11, 2020/13/13, 2025/15.5/15.5
} {
  \node[circlemark] at (\x,\y) {};
  \node[year, left=5pt] at (\x-0.1,\y-0.0) {\i};
}

% Events alternating left and right of the line
\node[event, above left=6pt and 6pt] at (1,1) {
  \textbf{The Beginning}\\
  McCullock-Pitts Neuron (1943)\\
  Turing Test (1947) \\
  Dartmouth Workshop (1956)
};

\node[event, below right=6pt and 6pt] at (3,3) {
  \textbf{Early Enthusiasm}\\
  Machines solve math, \\
  play games \\
  Lisp (1958) \\
  Neural net
};

\node[event, above left=6pt and 6pt] at (4.8,4.8) {
  \textbf{A Dose of Reality}\\
  Combinatorial explosion\\
  Early methods didn't scale\\
  Neural nets not ready\\
};

\node[event, below right=6pt and 6pt] at (6.3,6.3) {
  \textbf{Expert Systems Era}\\
  Prolog \\
  Rule-based knowledge\\
  Domain-specific reasoning\\
  AI industry emerges
};

\node[event, above left=6pt and 6pt] at (7.5,7.5) {
  \textbf{AI Winter Begins}\\
  Expert systems brittle \\
  Can't reason under \\
  uncertainty\\
};

\node[event, below right=6pt and 6pt] at (9,9) {
  \textbf{AI Return}\\
  Connectionist vs Symbolic\\
  ML from examples
};

\node[event, above left=6pt and 6pt] at (10.5,10.5) {
  \textbf{Big Data AI}\\
  Web-scale data: text, images\\
  Watson Jeopardy! (2011)\\
  Data-driven methods
};

\node[event, below right=6pt and 6pt] at (12.5,12.5) {
  \textbf{Deep Learning Boom}\\
  GPUs, DL layers\\
  ImageNet 2012 \\
  Vision, speech surpass \\
  human-level
};

\node[event, above left=6pt and 6pt] at (14,14) {
  \textbf{Modern AI}\\
  AlphaGo \\
  Multimodal models\\
  Reinforcement learning \\
  Transformers\\
};

\node[event, below right=6pt and 6pt] at (16,16) {
  \textbf{The Future}\\
  General Intelligence goals\\
  Unified learning across domains\\
  Toward human-like adaptability
};

\end{tikzpicture}
\end{document}
```

* AI Timeline (v2)
```raw_latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning}

\begin{document}
\begin{tikzpicture}[
  font=\sffamily,
  year/.style={font=\bfseries, text=blue!70!black},
  circlemark/.style={
    draw=blue!70!black, fill=white, line width=2pt, circle, minimum size=10pt
  },
  event/.style={
    align=left, text width=5.5cm, font=\small
  }
]

% Diagonal timeline
\draw[blue!70!black, thick] (0,0) -- (16,16);

% Adjusted coordinates: x and y increase together
\foreach \i/\x/\y in {
  1943/0/0, 1956/2/2, 1969/4/4, 1973/5.5/5.5, 1986/7/7, 1988/8/8,
  2001/9.5/9.5, 2011/11/11, 2020/13/13, 2025/15.5/15.5
} {
  \node[circlemark] at (\x,\y) {};
  \node[year, left=0pt] at (\x-0.2,\y-0.0) {\Large\i};
}

% Events with date ranges on the nodes
\foreach \title/\dates/\x/\y/\xshift/\yshift in {
  {The Dawn of AI}/{1943--1956}/0.3/0.3/-1.5/1.5,
  {The Birth of AI Research}/{1956--1969}/1.7/1.7/1.5/-1.5,
  {The First Reality Check}/{1966--1973}/3.1/3.1/-1.5/1.5,
  {The Rise of Expert Systems}/{1970--1987}/4.6/4.6/1.5/-1.5,
  {The First AI Winter}/{1987--1993}/6/6/-1.5/1.5,
  {Return of Neural Networks}/{1986--1990s}/7.4/7.4/1.5/-1.5,
  {The Probabilistic Turn}/{Late 1980s--2000s}/8.8/8.8/-1.5/1.5,
  {Machine Learning Matures}/{1990s--2000s}/10.2/10.2/1.5/-1.5,
  {Advances in Speech and Vision}/{1990s--2000s}/11.6/11.6/-1.5/1.5,
  {Reinforcement Learning Emerges}/{1990s--Present}/13/13/1.5/-1.5,
  {The Era of Big Data}/{2001--Present}/14.2/14.2/-1.5/1.5,
  {Deep Learning Revolution}/{2011--Present}/15.3/15.3/1.5/-1.5,
  {Reunification of AI Subfields}/{2010s--Present}/16.5/16.5/-1.5/1.5
} {
  \node[event, xshift=\xshift cm, yshift=\yshift cm] at (\x,\y) {\Large\textbf{\title}\\\dates};
}

\end{tikzpicture}
\end{document}
```

* The Beginning (1943-1956)
- **Artificial neuron**
  - Model (McCullock-Pitts 1943) based on:
    - Brain physiology
    - Propositional logic
    - Computation theory
  - Compute any function with connected neurons
    - Neuron on/off based on stimulation from neighboring neurons
    - Implement logical AND, OR, NOT with simple neuron networks

- **Alan Turing, 1947**
  - Turing test, machine learning, reinforcement learning
  - Create human-level AI:
    - Develop learning algorithms
    - Teach machine like a child

- **Birth of AI**
  - McCarthy organized first AI workshop (1956)
  - The Logic Theorist
    - Programs to "think non-numerically" and prove theorems
    - Newell and Simon (1956)

* Enthusiasm and Great Expectations (1952-1969)

- **Early years of AI were full of successes**
  - Until than computers could only do arithmetics
  - _"A machine can never do games, puzzles, IQ tests, ..."_
  - AI researchers showed machines could do that after another

- **General Problem Server**
  - Imitate human problem-solving
  - Consider sub-goals and possible actions

- **Program learned to play checkers**
  - Use reinforcement learning from victories and mistakes

- **Lisp (1958)**
  - High-level language used for 30 years in AI

- **First neural network**
  - 3000 vacuum tubes for 40 neurons
  - Marvin Minsky (1959)

- **MIT and Stanford**
  - Minsky at MIT
    - Focus on neural network
  - McCarthy at Stanford
    - Focus on representation, logic

* A Dose of Reality (1966-1973)
- Researchers were confident about AI's upcoming successes

- AI didn't succeed on real problems due to:
  - Solutions based on human problem-solving methods
  - Difficulty handling "combinatorial explosion":
    - Theorem proving handles small problems with brute force, but doesn't scale
  - Neural networks needed algorithms (e.g., backpropagation), compute power,
    and data

* Expert Systems (1969-1979)

- **Weak AI (Narrow AI)**
  - Performs specific tasks, not general reasoning
  - Operates in a limited, well-defined domain
  - Uses "weak methods" (search, logic) that struggle to scale
  - Improves with domain-specific knowledge

- **Expert Systems**
  - Known as "knowledge-based systems"
  - Combine weak methods with extensive domain knowledge as rules
  - Use inference engines to apply rules to facts
  - E.g., rule-based systems, logic programming (e.g., Prolog)

- **Commercial Adoption and Industry Growth (1980â€“)**
  - AI shifted to practical applications
  - Major US corporations deployed expert systems
  - AI emerged as a commercial industry

* (First) AI Winter (1980)

- AI overconfidence/hype didn't deliver

- **Reasons:**
  - Building/maintaining expert systems is difficult
  - Reasoning methods ignore uncertainty
  - Systems can't learn from experience
  - E.g., expert systems in medical diagnosis struggle with complex, variable
    patient data
  - E.g., early AI chess systems couldn't adapt to new strategies without manual
    updates

* Return of Neural Networks (1986-)

- Mid-1980s: Discovered back-propagation algorithm
  - Developed in early 1960s

- **Connectionist approach vs. Symbolic approach**
  - Connectionist: Neural networks
    - E.g., recognizing handwritten digits
  - Symbolic: General Problem Solver
    - E.g., solving logical puzzles with rules

- **Why connectionist approach**
  - Concepts not well-defined using symbolic axioms
    - Forms fluid internal concepts
    - Represents real-world complexity better
  - Neural networks learn from examples
    - Adjust parameters for improved predictions
  - E.g.,
    - Image recognition: Identify objects by learning from labeled images

* Probabilistic Reasoning and ML (1987-)

- **AI and scientific method**
  - Rigorous methods to test performance
  - E.g., speech recognition, handwritten character recognition

- **Benchmarks for progress**
  - Examples:
    - MNIST: Handwritten digit recognition
    - ImageNet: Image object recognition
    - SAT Competitions: Boolean satisfiability solvers

- **AI shifts ...**
  - From Boolean logic to probability
  - From hand-coded rules to machine learning
  - From a-priori reasoning to experimental results

* Progress in Speech Recognition

- **1970s: Ad-hoc approaches**
  - Various architectures and approaches were attempted
  - Rule-based systems with limited robustness
  - Cons: Ad-hoc, fragile

- **1980s: HMMs**
  - Hidden Markov Models (HMMs) became dominant
  - Pros: Strong theoretical foundation
  - Methods: Effective learning techniques
  - Data: Trained on large speech corpora
  - No claim humans use HMMs for speech recognition

* Bayesian Networks

- **Bayesian networks**
  - Judea Pearl, 1988
  - AI is linked with:
    - Probability
    - Decision theory
    - Control theory
  - Efficiently represent uncertainty
  - Provide rigorous reasoning

- **Examples**
  - Diagnosing diseases based on symptoms
  - Predictive text input in smartphones
  - Fraud detection in banking

* Reinforcement Learning

- **Reinforcement learning**
  - Sutton, 1988
  - Reinforcement Learning (RL) involves agents learning by interacting with an
    environment
  - Markov Decision Problems (MDPs) provide a mathematical framework for modeling
    decision-making

- **Examples**
  - RL: A robot learning to navigate a maze by receiving rewards for successful
    paths
  - MDPs: A game strategy modeled where each move influences the outcome with
    certain probabilities

* Reunification

- **Reunification of AI with**:
  - Data
  - Statistical modeling
  - Optimization
  - Machine learning

- **Many subfields of AI were re-unified**:
  - Computer vision
  - Robotics
  - Speech recognition
  - Multi-agent systems
  - NLP

* Big Data (2001-Present)

- **Focus shifts from algorithms to data**
  - For 60 years, AI focused on algorithms and models

  - For some problems, data availability matters more than algorithms, e.g.,
    - Trillions of English words
    - Billions of web images
    - Billions of speech and video hours
    - Social network data
    - Click stream data

  - Algorithms leverage large datasets

- In 2011, IBM's Watson beat human Jeopardy! champions

* Deep Learning (2011-Present)

- **Deep learning**
  - Use ML models with multiple layers of computing elements
  - Ideas known since 1970s, but then forgot
  - Success in handwritten digit recognition in 1990s

- **In 2011, DL took off**
  - Surge of interest in AI among researchers, students, companies, investors,
    government, and public
  - In 2012, a DL system showed dramatic improvement in `ImageNet` competition
    - Previous systems used handcrafted features

- Today, DL exceeds human performance in several vision and speech recognition
  tasks
- DL needs specialized hardware (e.g., GPU, TPU, FGPA) for parallel tensor
  operations

- **General Artificial Intelligence**
  - Universal algorithm for learning and acting, not just specialized tasks
    (e.g., driving, playing chess, recognizing speech)

## #############################################################################
## AI State of the Art
## #############################################################################

* Progress in AI Research

- **Between 2010 and 2019**
  - AI papers increased 20x
    - 1,000 $\to$ 20,000
  - Student enrollment in AI and CS increased 5x
    - 10,000 $\to$ 50,000
  - NeurIPS attendance increased 8x
    - 1,000 $\to$ 8,000
  - AI startups increased 20x
    - 100 $\to$ 2,000

- **Compute**
  - Training times dropped 100x in 2 years
  - AI computing power doubles every 3 months

* What Can AI Do Today? (1/2)

- **Robotic vehicles**
  - Waymo passed 10 million miles without serious accident

- **Legged locomotion**
  - BigDog recovers on ice
  - Atlas walks on uneven terrain, jumps on boxes, backflips

- **Autonomous planning and scheduling**
  - Space probes, Mars rovers

- **Machine translation**
  - Translates 100 languages with human-level performance

- **Speech recognition**
  - Real-time speech-to-speech with human-level performance
  - AI assistants

- **Recommendations**
  - ML recommends based on past experiences
  - Spam filtering 99.9% accuracy
  - E.g., Amazon, Facebook, Netflix, Spotify, YouTube

* What Can AI Do Today? (2/2)

- **Game playing**
  - 1997: Deep Blue defeated Kasparov
  - 2011: Watson beat Jeopardy! champion
  - 2017: AlphaGo beat Go champion
  - 2018: AlphaZero super-human in Go, chess with only rules, self-play
  - AI beats humans in videogames: Dota2, StarCraft, Quake

- **Image understanding**
  - Object recognition
  - Image captioning

- **Medicine**
  - AI equivalent to health care professionals

- **When AGI**
  - When will AI systems achieve human-level performance across all tasks?
  - Expert prediction average: 2099
    - Papers show that expert predictions no better than amateurs
    - Experts expected AI to take 100 years to beat humans in Go
  - Unclear if new breakthroughs or refinements needed

## #############################################################################
## Risks and Benefits of AI
## #############################################################################

* Benefits of AI
::: columns
:::: {.column width=55%}
- Our civilization is the product of human intelligence
  - Greater machine intelligence leads to better human society
  - _"First solve AI, then use AI to solve everything else"_

- **Benefits of AI and robots**
  - Free humanity from menial work
  - Increase production of goods and services
  - Expand human cognition
  - Accelerate scientific research, e.g.,
    - Cures for diseases
    - Solutions for climate change
    - Resource shortages
::::
:::: {.column width=40%}
![](lectures_source/figures/Lesson01_Friendly_AI.png)
::::
:::

* Risks of AI (1/2)

::: columns
:::: {.column width=55%}
- **Autonomous weapons**
  - Locate, select, eliminate human targets without intervention
  - Scalability: deploy a large number of weapons

- **Surveillance and persuasion**
  - AI (speech recognition, computer vision, natural language understanding) for
    mass surveillance
  - Tailoring information flows through social media to modify behavior

- **Biased decision making**
  - Misuse of ML can result in biased decisions due to societal bias
  - E.g., parole evaluations, loan applications
::::
:::: {.column width=40%}
![](lectures_source/figures/Lesson01_Terminator.png)

![](lectures_source/figures/Lesson01_Misinformation.png)
::::
:::

* Risks of AI (2/2)
- **Impact on employment**
  - Machines eliminate jobs
  - Rebuttal
    - Machines enhance productivity $\to$
    - Companies become more profitable $\to$
    - Higher wages
  - Counter-rebuttal
    - Wealth shifts from labor to capital, increasing inequality
  - Counter-counter-rebuttal
    - Past tech advances (e.g., mechanical looms) disrupted employment, but
      adaptation followed

- **Safety critical applications**
  - AI in safety-critical applications
    - E.g., self-driving cars, managing water supply or power grids
  - Avoiding fatal accidents is challenging
    - E.g., formal verification and statistical analysis insufficient
  - AI requires technical and ethical standards like other high-stakes fields

- **Cybersecurity**
  - AI defends against cyberattacks
    - E.g., detect unusual behavior patterns
  - AI contributes to malware development
    - E.g., use reinforcement learning for targeted phishing attacks

* Human-Level AI
- Human-level AI is "machines able to learn to do anything a human can do"
  - Aka AGI (Artificial General Intelligence)
- **Artificial Super-Intelligence**: Intelligence surpassing human ability in
  any domain and self-improving

* The Problem of Control
- Uncertain if humans can control machines more intelligent than them

- **King Midas problem**
  - King Midas turned everything he touched into gold, including food and family
  - Humans ask for something, get it, then regret it

- **Rebuttal**
  - If AGI arrived in a black box from space, exercise caution before opening
  - We design AI: if AI gains control, it's a "design failure"

* Solutions to Problem of Control
- Researchers and corporations developed voluntary self-governance principles for
  AI
  - Governments and international organizations established advisory bodies

- **Problems**
  - Preferences are not easy to invert and are inconsistent

- Put purpose into the machine even if objectives are unclear
  - Incentivize AI to switch off if uncertain about human objectives
  - Inverse reinforcement learning: AI observes human behavior to infer reward
    function
  - Cooperative Inverse Reinforcement Learning (CIRL)

* Cooperative Inverse Reinforcement Learning (CIRL)

- AI infers human goals based on actions

- **Observation**: Alice looks tired, sits on the couch, observes the messy
  table, and starts watching TV

- **Inference**: AI infers:
  - Alice is tired and wants to relax
  - Messy coffee table bothers her

- **Action**: AI:
  - Fetches a glass of water
  - Tidies up the coffee table without disturbing Alice

- **Feedback loop**: AI monitors Alice's reactions
  - If Alice is relaxed and happy, AI understanding is reinforced
  - If Alice is not happy, AI adjusts actions and improves inference
