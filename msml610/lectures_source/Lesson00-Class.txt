// notes_to_pdf.py --input lectures_source/Lesson1-Intro.txt --output tmp.pdf --type slides --skip_action cleanup_after --debug_on_error --toc_type navigation

::: columns
:::: {.column width=15%}
![](msml610/lectures_source/figures/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{MSML610 Class Mechanics}}$$**
\endgroup
\vspace{1cm}

**Instructor**: Dr. GP Saggese - `gsaggese@umd.edu`

# ##############################################################################
# MSML610
# ##############################################################################

* Invariants of a Class Lecture
- **Invariants**
  - Focus on intuition over math (unless necessary)
  - Emphasize realistic assumptions and numerical methods
    - Analytical solutions are so 1800s
  - Interactive Jupyter notebook tutorials for hands-on approach
    - Tutorials are mainly done at home
    - Videos of each tutorial will be added over time

- **Class flow**
  - Lessons alternate between slides, whiteboard, tutorials
  - 2:45 hours per class lessons
    - 50 mins
    - 10 break
    - 50 mins
    - 10 mins
    - 45 slides (Topic refresher!)

* Books of the Class
::: columns
:::: {.column width=65%}
- **Goal**: make the slides self-sufficient from recommended books
  - **Simple**
    - Burkov: _"The Hundred-Page Machine Learning Book"_ (2019)
    - Burkov: _"Machine Learning Engineering"_ (2020)
  - **Medium**
    - Abu-Mostafa et al.: _"Learning From Data"_ (2012)
    - Martin: _"Bayesian Analysis with Python"_ (2nd ed, 2021)
    - Russell et al.: _"Artificial Intelligence: A Modern Approach"_ (4th ed, 2020)
  - **Hardcore**
    - Hastie et al.: _"The Elements of Statistical Learning"_ (2nd ed, 2009)
    - Koller et al.: _"Probabilistic Graphical Models: Principles and Techniques"_ (2009)
    - Murphy: Machine Learning: _"A Probabilistic Perspective"_ (2012)
    - Sutton et al.: _"Reinforcement Learning: An Introduction"_ (2nd ed, 2018)

::::
:::: {.column width=40%}

![](msml610/lectures_source/figures/book_covers/Book_cover_Hundred_page_ML_book.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_Machine_Learning_Engineering.jpeg){ height=20% }

![](msml610/lectures_source/figures/book_covers/Book_cover_Learning_from_Data.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_Bayesian_analysis_with_Python.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_AIMA.jpg){ height=20% }

![](msml610/lectures_source/figures/book_covers/Book_cover_ML_A_probabilistic_perspective.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_Probabilistic_Graphical_Models.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_The_Elements_of_Statistical_Learning.jpg){ height=20% }
![](msml610/lectures_source/figures/book_covers/Book_cover_Reinforcement_learning.jpg){ height=20% }
::::
:::

* Grading
- **Quizzes** (40%)
  - Multi-choice quizzes on previous 2 lessons
  - 4-5 quizzes to make you study during the semester and don't cram

- **Final Project** (60%)
  - A comprehensive application of course concepts
  - Python project selected from a list of topics

* Class Projects
- The project is _"Build $X$ with $Y$"_, where $X$ is a "use case" and $Y$ is a
  "technology"
  - Study and describe technology $Y$
  - Implement a use case $X$ using the technology $Y$
  - Create Jupyter notebooks to demo your project
  - Commit code to GitHub and contribute to open-source repo
  - Write a blog entry
  - Present your project in a video

- There is a list of $X$ and $Y$ you can pick from, e.g.,
  - Statistical learning
  - Big data
  - LLMs
  - Deep learning
  - ...

- Each project:
  - Is individual or group ($n < 4$)
  - Has different levels of difficulty

* Links

- [\textcolor{blue}{\underline{ELMS}}](https://umd.instructure.com/courses/1391619/pages/homepage)

- [\textcolor{blue}{\underline{Syllabus}}](https://docs.google.com/document/d/1YXCrqh6KGg3xm4-Lr4QGdBnjeWEfkqz67FHNHB_rdAk/edit?tab=t.0#heading=h.278ryn4xodsb)
  - Schedule
  - GitHub project
  - Class FAQs

- [\textcolor{blue}{\underline{Project specs}}](TBD)

// TODO: Add link to project specs

* Yours Truly
::: columns
:::: {.column width=50%}

- **GP Saggese**
  - 2001-2006, PhD / Postdoc at the University of Illinois at Urbana-Champaign
  - [\textcolor{blue}{\underline{LinkedIn}}](https://www.linkedin.com/in/gpsaggese/)
  - [\textcolor{blue}{\underline{gsaggese@umd.edu}}](gsaggese@umd.edu)
- **University of Maryland**:
  - 2023-, Lecturer for UMD DATA605: Big Data Systems
  - 2025-, Lecturer for UMD MSML610: Advanced Machine Learning
- **In the real-world**
  - Research scientist at NVIDIA, Synopys, Teza, Engineers' Gate
  - 3x AI and fin-tech startup founder (ZeroSoft, June, Causify AI)
  - 20+ academic papers, 2 US patents
::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/GP_in_coding_state.png)
::::
:::

# ##############################################################################
# Class Map
# ##############################################################################

// TODO(gp): Refresh this once the slides are complete
// lectures_source/get_syllabus.sh

* 1. Intro
- A Map of Machine Learning
- What Is Artificial Intelligence
  - AI
  - Machine Learning
  - AI vs ML vs Deep-Learning
  - The Foundation of AI
  - Brief History of AI
  - AI State of the Art
  - Risks and Benefits of AI

* 2. Machine Learning Techniques
- Paradigms
- Techniques
  - Machine Learning in Practice
  - How to Do Research
    - Simple Is Better
    - Research Methodology
  - Pipeline Organization
  - Input Processing
  - Learning Algorithms
    - Gradient Descent
    - Stochastic Gradient Descent
  - Performance Metrics
    - Precision and Recall
  - Model Selection
  - Aggregation
    - Bagging
    - Boosting
    - Stacking

* 3. Knowledge Representation
- Knowledge Representation
  - Basics of Knowledge Representation
  - Examples of Logic
  - Logical Agents
  - Ontologies
  - Reasoning in Ontologies
- Propositional logic
- First-order Logic
- Non-classical Logics
- Description Logics
  - Semantic Web

* 4. Machine Learning Models
- Models
  - Naive Bayes
  - Decision trees
  - Random forests
  - Linear models
  - Perceptron
  - Logistic regression
  - LDA, QDA
  - Kernel methods
  - Support vector machines
  - Similarity-based models
  - Clustering
  - Anomaly detection

* 5. Machine Learning Theories
- Is machine learning possible?
- Growth function
- The VC dimension
- Overfitting
- Bias Variance Analysis
- Learning curves
- Learn-validation approach
  - Train / test
  - Cross-validation

* 6. Bayesian Statistics
- Logic-Based AI Under Uncertainty
- Probabilistic Reasoning
  - Conditional Independence
  - Bayesian Networks
  - Semantics of Bayesian Networks
  - Constructing a Bayesian Network
  - Exact Inference in Bayesian Networks
  - Approximate Inference in Bayesian Networks
    - Direct sampling methods

* 7. Probabilistic Programming
- Concepts
- Coin Example
  - Analytical Approach
  - Communicating a Bayesian Analysis
  - Probabilistic Programming
- Posterior-Based Decisions
  - Chemical Shift: Example
  - Posterior Predictive Checks
    - Robust Inference
- Groups Comparison
- Hierarchical Models
- Simple Linear Model
  - Logistic Regression
- Multiple linear regression
- Comparing Models
    - Posterior Predictive Checks
  - The Balance Between Simplicity and Accuracy
  - Measures of Predictive Accuracy
    - Information Criteria
    - Cross-Validation
    - Bayes Factors and Information Criteria
  - Regularizing priors
  - Regularizing Priors
  - Mixture Models

* 8. Reasoning Over Time
- Reasoning over time
- HMMs
- Markov random fields
- Markov logic network
- State space models and Kalman filter
  - G-h filter
  - Discrete Bayes filter
- Dynamic Bayesian networks
- State space model
- Variational Inference
  - Expectation-Maximization (EM) Algorithm

* 9. Causal Inference
- Causal AI
  - Why Causal AI?
  - Concepts in Causal AI
  - Variables
  - Paths
  - The Ladder of Causation
  - Correlation vs causation models
- Business processes around data modeling
  - Modeling processes
  - Roles

* 10. Timeseries Forecasting
- Time Series
  - Basic definition
  - Time series operators
  - Time series decomposition
- Classical Methods
  - Simple models for stochastic process
  - Autoregressive models
  - Moving average models
  - ARMA(p, q) process
  - ARIMA model
  - ARCH model

* 11. Probabilistic Deep Learning
- Neural networks
  - Biological inspiration
  - Neural networks
- Advanced Neural Network Architectures
  - Convolutional networks
  - Recurrent Neural Networks (RNNs)
  - Deep learning learning algorithms
  - Deep learning architectures
- Fundamentals of Deep Learning
- Training Deep Neural Networks
- Interpretability and Explainability
- Deep Generative Models
- Bayesian Deep Learning
- Deep Probabilistic Models
- Uncertainty Quantification
- Probabilistic Programming and Inference
- Modern Research Frontiers
- Bonus Topics

* 12. Reinforcement Learning
- Sequential decision problems
  - Utilities over time
  - Algorithms for MDPs
- Reinforcement learning
  - Passive reinforcement learning
  - Active reinforcement learning
  - Generalization in reinforcement learning
  - Policy search
- Fundamentals
- Classical Methods
- Exploration Strategies
- Policy Gradient Methods
- Value Function Approximation
- Deep Reinforcement Learning
- Model-Based Reinforcement Learning
- Advanced Topics
- Applications

* Refresher: Probability
- Probability
  - Probability definition
  - Probability measure
  - Independent events
  - Conditional probability
  - Law of total probability
  - Bayes theorem
- Random variables
  - Random variables
  - CDF, PMF, PDF of Random Variables
  - Joint distributions
  - Marginal distributions
  - Independent RVs
  - Conditional PDF RVs
- Mathematical expectation of RVs
  - Mean
  - Variance and covariance
  - Statistics of RVs
- Probability inequalities
- Statistical Inference
  - Definitions
  - Sample mean
  - Sample variance
  - Asymptotics
  - Confidence intervals
  - Hypothesis testing
  - Multiple hypothesis testing
  - Estimating CDF and statistical functional
  - Bootstrap

* Refresher Probability Distributions
- Interesting RVs
  - Bernoulli
  - Binomial
  - Gaussian
  - Log-Normal
  - Poisson
  - Chi-square
  - Student's t-distribution
- Probability inequalities

* Refresher Linear Algebra
- Linear algebra
  - Vector and vector spaces
  - Affine spaces
  - Vectors and matrices
  - Linear functions
  - Connections between Machine Learning and Linear Algebra

* Refresher Information Theory
- Information theory
  - Entropy
    - Kullback-Leibler divergence
  - Connections between Information Theory and ML

* Refresher Game Theory
- Game theory
  - Connections between Machine Learning and Game Theory

* Refresher: Numerical Optimization
- Optimization / numerical methods

* Refresher: Stochastic Processes
- Stochastic processes
