::: columns
:::: {.column width=15%}
![](msml610/lectures_source/figures/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{Probabilistic Programming}}$$**
\endgroup
\vspace{1cm}

::: columns
:::: {.column width=75%}
\vspace{1cm}
**Instructor**: Dr. GP Saggese - `gsaggese@umd.edu`

**References**:

- AIMA (Artificial Intelligence: a Modern Approach)
  - Chap 15: Probabilistic programming

- Martin, Bayesian Analysis with Python, 2018 (2e)

::::
:::: {.column width=20%}

![](msml610/lectures_source/figures/book_covers/Book_cover_AIMA.jpg){ height=20% }

::::
:::

# Concepts

// From Martin.Bayesian_Analysis_with_Python.2e.txt

// TODO: Merge AIMA 15.1, Relational probability models 8642

// notes/IN_PROGRESS.math.Artificial_intelligence.Russell.4e.2020.txt
// notes/math.Probabilistic_programming_for_hackers.DavidsonPilon.2017.txt
// notes/_IN_PROGRESS/book.2018.Martin.Bayesian_Analysis_with_Python.2e.txt
// ./notes/IN_PROGRESS.math.Bayesian_data_analysis.Gelman.2014.txt

// From notes/_IN_PROGRESS/book.2018.Martin.Bayesian_Analysis_with_Python.2e.txt
// 1, Thinking probabilistically

* EDA vs Inference
- **Exploratory data analysis**
  - Summarize, interpret, check data
  - Visually inspect the data
  - Compute descriptive statistics
  - Communicate results

- **Inferential statistics / inference**
  - Draw insights from a limited set of data
  - Make predictions for future unobserved data points
  - Understand a phenomenon
  - Choose among competing explanations for the same observations

// TODO(gp): Add figure
// TODO(gp): Move this to Techniques?

* Good vs Bad Way to Do Statistics
- **Bad** ![Smile Emoji](emoji/angry_devil.png){ width=12px }
  - Learn a collection of "statistical recipes"
    - Make assumption / approximate to make math workable
  - Given data and problem
    - Pick one recipe
    - Try until you get a "low" p-value
  - For machine learning
    - Iterate until you get a "good" fit on out-of-sample data

- **Good** ![Smile Emoji](emoji/emoji_smile.png){ width=12px }
  - General approach to statistical inference (Bayesian statistics)
    - Remove limitations from closed analytical form
  - Probabilistic approach unifies (seemingly) disparate methods
    - E.g., statistical methods and machine learning
    - E.g., `statsmodels` linear regression vs `sklearn` decision tree
    - Deep unity of different recipes
  - Modern tools (e.g., PyMC3) solve previously unsolvable models

// TODO(gp): Make it a table?

// ## 1.2, Working with data

* Data
- Data **comes from**:
  - Experiments
  - Simulations
  - Surveys
  - Field observations

- Data is stochastic due to **uncertainty**
  - Ontological: system is intrinsically stochastic
  - Technical: measurement precision is limited or noisy
  - Epistemic: conceptual limitations in understanding

- Collecting data is **costly**
  - Consider questions before collecting data
  - Experiment design is a branch of statistics for data collection

- Data is **rarely clean and tidy**

- Data needs to be **interpreted** through mental and formal models

// ## 1.3, Bayesian modeling

* Models
- **Models** are simplified descriptions of a given system/process
  - A more complex model is not always a better one
  - VC dimension made it mathematical precise
    - _"You need at least 10 data points per effective degree of freedom of the
      hypothesis set"_

- **Goals**
  - Capture the most relevant aspects of the system
  - Ignore minor details

* Bayes' Theorem: Recap
- **\black{Bayes' theorem}** posits that for model parameters $\theta$ and data
  $X$
  $$
  \red{\Pr(\theta | X)}
  = \frac{\teal{\Pr(X | \theta)} \cdot \blue{\Pr(\theta)}}{\violet{\Pr(X)}}
  $$
  where:
  - **\red{$\Pr(\theta | X)$}**
    - **\black{Posterior}**: probability for parameters $\theta$ after seeing
      data $X$
  - **\teal{$\Pr(X | \theta)$}**
    - **\black{Likelihood}** (aka "statistical model"): plausibility of data $X$
      given parameters $\theta$
  - **\blue{$\Pr(\theta)$}**
    - **\black{Prior}**: knowledge about parameter $\theta$ before any data
  - **\violet{$\Pr(X)$}**
    - **\black{Evidence}** ("marginal likelihood"): probability of observing
      data $X$
    - "Marginal" as it averages over all possible parameter values

- In other words:
  $$
  \red{Posterior}
  = \frac{\teal{Likelihood} \cdot \blue{Prior}}{\violet{Evidence}}
  $$

* Bayesian Models
- **Probability** measures uncertainty about parameters

- **Bayes' theorem** updates probabilities with new data, reducing uncertainty
  (hopefully)
  $$
  \Pr(hyp | data) = \frac{\Pr(data | hyp) \Pr(hyp)}{\Pr(data)}
  $$

- **Bayesian modeling workflow**
  1. Design a model using probabilities based on data and assumptions
     - Assumptions on data generation
     - Model can be a crude approximation
  2. Apply Bayes' theorem to "condition" the model on data
  3. Validate model against:
     - Data
     - Subject expertise
     - Related models
  - Steps may involve backtracking:
    - Correct coding errors
    - Improve model
    - Gather more or different data

# Coin Example

## #############################################################################
## Analytical Approach
## #############################################################################

* Coin Example: Problem
- **Problem**:
  - Toss a coin $N$ times
  - Record the number of heads $Y$ and tails $N - Y$
  - Question: _"How biased is the coin?"_

- There is **true uncertainty**
  - An underlying parameter exists, but it is unknown
  - $\theta$ represents the coin bias
    - $0$: always tails
    - $1$: always heads
    - $0.5$: half tails, half heads

- **Model assumptions**:
  - Independent Identically Distributed (IID)
    - Independence: coin tosses don't affect each other
    - Identically distributed: coin's bias is constant
  - Likelihood $Y | \theta$ as a binomial distribution
    - Probability of $Y$ heads out of $N$ tosses, given $\theta$
  - Prior $\theta$ as a beta distribution
    - Adopts several shapes
    - Beta is the conjugate prior of the binomial distribution

* Binomial Distribution

::: columns
:::: {.column width=40%}
Probability of $k$ heads out of $n$ tosses given bias $p$

\begin{align*}
  & X \sim Binomial(n, p) \\
  & \Pr(k) = \frac{n!}{k! (n - k)!} p^k (1 - p)^{n-k} \\
\end{align*}

::::
:::: {.column width=55%}
![](msml610/lectures_source/figures/Lesson07_Binomial_distribution.png)
::::
:::

* Beta Distribution

::: columns
:::: {.column width=50%}
- Continuous PDF in [0, 1]

- Adopts several shapes
  - Uniform, increasing, decreasing, Gaussian-like, U-like
  - $\alpha$: "success" parameter
  - $\beta$: "failure" parameter
  - $\alpha > \beta$: Skews toward 1, higher probability of success
  - $\alpha = \beta$: Symmetric, centered around 0.5

- Models probability or proportion
  - E.g., probability of success in a Bernoulli trial $\theta$

- Beta is the conjugate prior of the binomial distribution
::::
:::: {.column width=50%}

\begin{align*}
  & X \sim Beta(\alpha, \beta) \\
  & \Pr(\theta)
    = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)}
    \theta^{\alpha - 1} (1 - \theta)^{\beta - 1} \\
\end{align*}

![](msml610/lectures_source/figures/Lesson07_Beta_distribution.png)
::::
:::

* Conjugate Prior of a Likelihood
- **Conjugate prior** is a prior that, when combined with a likelihood, returns a
  posterior with the same functional form as the prior

  - E.g.,

  | **Prior** | **Likelihood** | **Posterior** |
  | --------- | -------------- | ------------- |
  | Beta      | Binomial       | Beta          |
  | Normal    | Normal         | Normal        |

- **Properties**
  - Prior and posterior have the same distribution
  - Posterior has a closed analytical form
    - Update parameters from the prior using data in multiple iterations
  - Ensures tractability of the posterior

* Coin Example: Analytical Solution
- The **\red{posterior}** is proportional to **\green{likelihood}** $\times$
  **\blue{prior}**
  $$\red{\Pr(\theta | y)} \propto \green{\Pr(y | \theta)} \blue{\Pr(\theta)}$$

- Substituting **\green{likelihood}** with a Binomial and **\blue{prior}** with a
  Beta
  \begin{align*}
  & \Pr(\theta \mid Y)
  \\
  & = \underbrace{\frac{N!}{y!(N - y)!} \theta^y (1 - \theta)^{N - y}}_{\text{likelihood}}
  \underbrace{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)}
   \theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}_{\text{prior}}
  \\
  & \propto
  \underbrace{\theta^y (1 - \theta)^{N - y}}_{\text{likelihood}}
  \underbrace{\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}_{\text{prior}}
  \\
  & = \theta^{y + \alpha - 1} (1 - \theta)^{ N - y + \beta - 1}
  \\
  & = \text{Beta} \left( \alpha_{\text{prior}} + y, \beta_{\text{prior}} + N - y \right)
  \\
  \end{align*}

\vspace{-0.7cm}
- This is how **\black{the posterior is updated}** given the data

* Coin Example: Effect of Priors (1/2)

::: columns
:::: {.column width=40%}
- The true (unknown) value of the coin bias is 0.35

- Start with 3 different priors and see how the model is updated

- \red{Red}: uniform prior
  - All bias values equally probable
- \green{Green}: Gaussian-like prior around 0.5
  - Coin mostly unbiased
- \blue{Blue}: skewed towards tail
  - Coin biased

- Apply data to update the posterior distribution

- Update model
::::
:::: {.column width=60%}

![](msml610/lectures_source/figures/Lesson07_Updating_the_prior.png)
::::
:::

* Coin Example: Effect of Priors (2/2)
::: columns
:::: {.column width=40%}
- Outcome of Bayesian analysis is posterior distribution, not a single value
- Spread of posterior proportional to uncertainty
- Spread decreases with more data
- Spread decreases faster if aligned with prior
- With enough data, models with different priors converge to same result
- Applying posterior sequentially or at once yields same result
::::
:::: {.column width=55%}

![](msml610/lectures_source/figures/Lesson07_Updating_the_prior.png)
::::
:::

## Frequentist vs Bayesian

* Frequentist Approach vs Priors
- **Detractors of Bayesian approach** complain that:
  - _"One should let the data speak"_
  - The prior doesn't let the data speak for itself

- ![](emoji/balance_scale.png){ width=14px } **Counterpoints** 
  - _"Data doesn't speak, but murmurs"_
    - Data doesn't have meaning per-se
    - Make sense of data only in context of models (e.g., mental models,
      mathematical models)
    - A prior is a mathematical model

  - Every statistical model has a prior, even if not explicit
    - E.g., maximum likelihood estimate (MLE) in frequentist approach corresponds
      to a uniform prior and using the mode of the posterior
    - Frequentist statistics still makes assumptions (i.e., has a prior), but are
      hidden
    - E.g, MLE is a point-estimate, not a distribution of plausible values

* Advantages of Using Prior

- **Assumptions are clear and explicit**
  - Instead of hidden by frequentist / hack-ey ML approach

- **Prior encourages deeper analysis** of problem and data
  - Forces understanding before seeing data

- Posterior, averaged over priors, is robust and **less prone to overfitting**

- Spread of distribution measures **uncertainty**

- Well-chosen prior simplifies and **speeds up inference**
  - _"When you encounter computational problems, there's often an issue with your
    model"_ (Gelman, 2008)

* How to Choose Priors
- **Weakly-informative priors** (aka "flat", "vague", "diffuse priors")
  - Provide minimal information
    - Coefficient of linear regression centered around 0: $\beta \sim Normal(0, 10)$

- **Regularizing priors**
  - Known information about the parameter
    - Parameter is positive: $\sigma \sim HalfCauchy(0, 5)$
    - Parameter close to zero, above/below a number, or in a range
    - $\beta \sim Laplace(0, 1)$ (lasso prior) encourages sparsity
    - $\beta \sim Normal(0, 1)$ discourages extreme values

- **Informative priors**
  - Strong priors from previous knowledge (expert opinion, studies)
    - From experimental data: $\beta_1 \sim Normal(2.5, 0.5^2)$
    - From previous data, about 5% of cases positive: $p \sim Beta(2, 38)$

- **Prior elicitation**
  - Compute least informative distribution given constraints
    - Estimate distribution using maximum entropy to satisfy constraints
    - E.g., beta distribution with 90% of mass between 0.1 and 0.7

* Communicating the Model of a Bayesian Analysis
::: columns
:::: {.column width=65%}
1. **Communicate assumptions / hypothesis**
   - Describe priors and probabilistic models
   - E.g., coin-flip distributions:
     \begin{equation*}
       \begin{cases}
       \theta \sim \Beta(\alpha, \beta) \\
       y \sim Binomial(n=1, p=\theta) \\
       \end{cases}
     \end{equation*}

2. **Communicate Bayesian analysis result**
   - Describe posterior distribution
   - Summarize location and dispersion
   - Mean (or mode, median)
   - Std dev
     - Misleading for skewed distributions
   - Highest-posterior density (HPD)
     - Shortest interval containing a portion of probability density (e.g., 95% or
       50%)
     - Amount is arbitrary (e.g., `ArviZ` defaults to 94%)

::::
:::: {.column width=30%}

Kruschke diagram
![](msml610/lectures_source/figures/Lesson07_Kruschke_diagram.png){ height=50%}
::::
:::

* Confidence Intervals vs Credible Intervals
- People confuse:
  - Frequentist **confidence intervals** with
  - Bayesian **credible intervals**

- In the frequentist framework, there is a true (unknown) parameter value
  - A **confidence interval** may or may not contain the true parameter value
  - Interpretation of a 95% confidence interval
    - ![](emoji/wrong.png){ width=12px }
      No: _"There is a 95% probability that the true value is in this interval"_
    - ![](emoji/check_mark.png){ width=12px }
      Yes: _"If repeated many times, 95% of intervals would contain the true
      value"_

- In the Bayesian framework, parameters are random variables
  - Interpretation of a 95% **Bayesian credible interval**
    - _"There is a 95% probability that the true parameter lies within this
      interval, given the observed data"_
    - Bayesian **credible interval** is intuitive

// TODO: Build an example

* Confidence Intervals vs Credible Intervals (ELI5)

- **Confidence Interval (Frequentist)**
  - Imagine fishing in a lake without seeing the fish
  - You throw your net
  - 95% confidence interval: _"If I threw this net 100 times, about 95 nets
    would catch the fish."_
  - Important: Once the net is thrown, it either caught the fish or not. The 95%
    makes sense across many attempts

- **Credible Interval (Bayesian)**
  - Imagine a magical map showing where fish _probably_ are, based on past
    observations
  - 95% credible interval: _"Given my map, there's a 95% chance the fish is
    inside this part of the lake."_
  - The fish's location is uncertain, and probability describes your
    belief

- **Key Difference**
  - Confidence interval (Frequentist): Probability from repeating
    experiments
    - It's about the procedure, not the specific interval
  - Credible interval (Bayesian): Probability describes your belief
    about the value, given the data
    - It's about _this interval_

// 2, Programming probabilistically

## #############################################################################
## Probabilistic Programming
## #############################################################################

* Bayesian Statistics
::: columns
:::: {.column width=60%}
- Given:
  - The **"knows"**
    - Model structure (modeled as a graph of probability distributions)
    - Data, observations (modeled as constants)
  - The **"unknowns"**
    - Model parameters (modeled as probability distributions)
- Use Bayes' theorem to:
  - Condition unknowns to knowns
  - Reduce the uncertainty about the unknowns

::::
:::: {.column width=35%}

```graphviz
digraph BayesTheorem {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    // Node styles
    knowns       [label="Knowns", fillcolor="#A6C8F4"];
    unknowns_in  [label="Unknowns", fillcolor="#A6E7F4"];
    bayes_box    [label="Bayes' Theorem", fillcolor="#FFD1A6"];
    unknowns_out [label="Updated Unknowns", fillcolor="#B2E2B2"];

    // Force ranks
    { rank=same; knowns; unknowns_in }

    // Edges
    knowns      -> bayes_box;
    unknowns_in -> bayes_box;
    bayes_box   -> unknowns_out;
}
```

::::
:::

- **Problem** 
  - Most probabilistic models are analytically intractable

- **Solution**
  - Probabilistic programming
    - Specify a probabilistic model using code
    - Solve models using numerical techniques

* Probabilistic Programming Languages
- **Steps**:
  1. Specify models using code
  2. Numerical models solve inference problems without need of user to understand
     how
     - Universal inference engines
     - `PyMC3`: flexible Python library for probabilistic programming
     - `Theano`: library to define, optimize, evaluate mathematical expressions
       using tensors
     - `ArviZ`: library to interpret probabilistic model results

- **Pros**:
  - Compute results without analytical closed form
  - Treat model solving as a black box
  - Focus on model design, evaluation, interpretation

- **Probabilistic programming languages** impact like Fortran on scientific
  computing
  - Build algorithms but ignore computational details

* Coin Example: Numerical Solution (1/3)

- It's a synthetic example!
  - Assume you know the true value of $\theta$ (not true in general)

- **Workflow**
  - Model the prior $\theta$ and the likelihood $Y | \theta$
    \begin{equation*}
      \begin{cases}
      \theta \sim \text{Beta}(\alpha = 1, \beta = 1) \\
      Y \sim \text{Binomial}(n = 1, p = \theta) \\
      \end{cases}
    \end{equation*}
  - Observe samples of the variable $Y$
  - Run inference
  - Generate samples of the posterior
  - Summarize posterior
     - E.g., Highest-Posterior Density (HPD)
  - ...

* Coin Example: Numerical Solution (2/3)

::: columns
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Coin_example_numerical_solution.png)
::::

:::: {.column width=30%}
\begingroup
\scriptsize

- Generate data from ground truth model
- Build PyMC model matching mathematical model
- PyMC uses NUTS sampler, computes 4 chains
- No trace diverges
- Kernel density estimation (KDE) for posterior (should be Beta)
- Traces appear "noisy" and non-diverging (good)
- Numerical summary of posterior: mean, std dev, HDI
- $\EE[\hat{\theta}] \approx 0.324$
- $\Pr(\hat{\theta} \in [0.031, 0.653]) = 0.94$

\endgroup
::::
:::

* Coin Example: Numerical Solution (3/3)

::: columns
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Coin_example_numerical_solution_2.png)
::::

:::: {.column width=30%}
\begingroup
\small

- Compute single KDE for all chains
- Rank plot to check results
- Histograms should look uniform, exploring different (and all) posterior regions
- Plot single KDE with all statistics

\endgroup
::::
:::

# Posterior-Based Decisions

* Posterior-Based Decisions
- Sometimes describing the posterior is not enough
  - You need to make decisions based on our inference

- E.g., is the coin fair ($\theta = 0.5$) or biased?
  - Since $\EE[\hat{\theta}] = 0.324$ it seems that the coin is biased
  - You can't rule out that the coin in unbiased since
    - $HPI = [0.03, 0.65]$
    - $0.5 \in HPI$

- If you want a sharper decision, you need to:
  - Collect more data to reduce the spread of the posterior
  - Define a more informative prior

* Savage-Dickey Density Ratio
- The Savage-Dickey ratio tests a point null-hypotheses in Bayesian inference

- **Idea**: compare prior and posterior densities at a single point $\theta_0$
  $$
  BF_{01} = \frac{p(\theta_0 | H_1)}{p(\theta_0 | \mathcal{D}, H_1)}
  $$
  where:
  - $p(\theta_0 | H_1)$ is the _prior_ density $\theta$ under the alternative
    hypothesis $H_1$, evaluated at $\theta_0$
  - $p(\theta_0 | \mathcal{D}, H_1)$ is the _posterior_ density $\theta$ under
    $H_1$ evaluated at $\theta_0$

\begingroup \scriptsize
| **Bayes Factor (BF)** | **Interpretation**  |
|-------------------|-------------------------|
| 1 - 3           | Not enough evidence       |
| 3 - 10          | Substantial evidence      |
| 10 - 100        | Strong evidence           |
| > 100           | Decisive evidence         |
\endgroup

- **Intuition**: this ratio shows how much data changes belief about $\theta_0$
  - If posterior density at $\theta_0$ is much smaller than prior density, Bayes
    factor suggests strong evidence against $H_0$

* Savage-Dickey Density Ratio: Example

::: columns
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Savage_Dickey.png)

::::
:::: {.column width=30%}
- $H_0$: "coin is fair"
- The prior for $H_0$ is 0.87
- The posterior for $H_0$ is 1.15
- $BF_{10} = $

::::
:::

// TODO: improve

* ROPE: Region of Practical Equivalence
- **ROPE** = an interval for a parameter where all values inside are considered
  "equivalent"
  - $H_0$: _"coin is fair"_ iff $\theta = 0.5$ is impractical
  - ROPE: $\theta \in [0.45, 0.55]$ is equivalent to $0.5$

- **Hypothesis testing with ROPE and HPI**
  - Compare ROPE (Region Of Practical Equivalence) with HPI (Highest-Posterior
    Interval)
    - If HPI is within ROPE, no effect: $H_1$ is rejected
    - If HPI is outside ROPE, there is an effect: $H_0$ is rejected
    - If HPI overlaps with ROPE, result is inconclusive

- Decide ROPE before analysis based on domain knowledge
  - Picking it after analysis is like picking the p-value threshold after seeing
    the p-value

* Loss Function: Motivation
- You need to make decisions based on our inference

- For many problems, decision cost is asymmetric
  - E.g., cost of a bad decision > benefit of a good decision
  - E.g., vaccines may cause overreaction, but benefits outweigh risks

- To make the best decision, measure:
  - Benefits of a correct decision
  - Cost of a mistake
  - Decide trade-off between benefits and costs using a loss function
  - Use loss we function for decisions

- Loss quantifies _"how bad is an estimation mistake?"_
  - Larger loss indicates worse estimation

* Loss Function
- Aka "cost function"
  - The inverse is known as "objective", "fitness", "utility function"

- Use a function to measure the difference between:
  - The true value $\theta$; and
  - The estimated value $\hat{\theta}$

  \begingroup \small
  | **Loss**       | **Expression**               | **Point estimate**    |
  | -------------- | ---------------------------- | --------------------- | 
  | Quadratic loss | $(\theta - \hat{\theta})^2$  | Mean of posterior     |
  | Absolute loss  | $|\theta - \hat{\theta}|$    | Median of posterior   |
  | 1-0 loss       | $I(\theta \ne \hat{\theta})$ | Mode of posterior     |
  \endgroup

- Making decisions in Bayesian statistics using loss function
  - Goal: pick a single value $\hat{\theta}$
  - You don't know the true value $\theta$
  - Estimate $\theta$ in terms of the posterior distribution
  - Find the value $\hat{\theta}$ that minimizes the expected loss function

* Use of Gaussians in Bayesian Analysis
- Aka "normal" distribution

- **Pros**:
  - Gaussians are easy to work with and abundant in nature
  - Average of large sample size tends to be Gaussian (CLT)
  - Many phenomena approximated using Gaussians (since they are average of
    effects)
  - Conjugate prior of Gaussian is Gaussian

- Important to relax assumption of Gaussianity

## Chemical Shift: Example

* Chemical Shift

::: columns
:::: {.column width=50%}
- Nuclear magnetic resonance (NMR)
  - Used to study molecules of living things
  - Measures observable quantities related to unobservable molecular properties
    (e.g., chemical shift)

- Data looks Gaussian with a couple of outliers
::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift.png)
::::
:::

* Chemical Shift: Example

::: columns
:::: {.column width=50%}
- Assume Gaussian is a decent approximation of the data

- The likelihood $y | \mu, \sigma$ comes from a normal distribution:
  $$Y \sim N(\mu, \sigma)$$

::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift.png)
::::
:::

- Priors for mean and sigma of $Y$
  1. Mean from uniform distribution $U(l, h)$:
     $$
     \mu \sim U(l, h)
     $$
     - Set $\mu$ larger than data range, e.g., $[40, 75]$
  2. Std dev from half-normal distribution (i.e., a regular normal, but
     restricted to non-negative values):
     $$
     \sigma \sim HalfNormal(0, \sigma_\sigma)
     $$
     - If unknown, set $\sigma_\sigma = 10$

* Chemical Shift: PyMC

![](msml610/lectures_source/figures/Lesson07_Chemical_shift_pymc_solution1.png)

- The code is one-to-one with the model:
  \begin{equation*}
    \begin{cases}
    \mu \sim U(l=40, h=75) \\
    \sigma \sim HalfNormal(0, \sigma_\sigma=10) \\
    Y \sim N(\mu, \sigma) \\
    \end{cases}
  \end{equation*}

- Get 1000 samples from the posterior

* Chemical Shift: PyMC

::: columns
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_pymc_solution2.png)
::::
:::: {.column width=30%}

- Compute 4 traces for 2 variables $\mu$, $\sigma$
  - Results are well-formed
  - $\mu \in [52.55, 54.45]$
  - $\sigma \in [2.86, 4.23]$
::::
:::

## Posterior Predictive Checks

* Samples from Posterior Distribution
- Given a \blue{posterior distribution $\Pr(\theta | y)$}, you can generate
  predictions \red{$\tilde{y}$} based on the data \green{$y$} and the estimated
  parameters $\hat{\theta}$:

  $$
  \Pr(\red{\tilde{y}} | \green{y})
  = \int_{\theta} \Pr(\tilde{y} | \hat{\theta}) \Pr(\theta | y) d\theta
  = \int \text{model} \times \text{posterior}
  $$
// TODO(gp): Is it \hat{\theta}?

- This is called the "**\red{posterior} \blue{predictive} distribution**" as it
  predicts \blue{future data} using the \red{posterior distribution}

- Conceptually:
  - Sample a value of $\theta$ from the posterior $\Pr(\theta | y)$
  - Feed the value of $\theta$ to the likelihood $\Pr(y | \theta)$
  - Obtain $\tilde{y}$

- This process has two sources of uncertainty:
  - Parameter uncertainty
    - Captured by the posterior $\Pr(\theta | y)$
  - Sampling uncertainty
    - Captured by the likelihood $\Pr(y | \theta)$

* Posterior Predictive Check (PPC)
- **Intuition**: can the model reproduce observed data?

- PPC approach:
  - Generate predictions $\tilde{y}$ with observed data $y$
  - Check for consistency

- Models should always be checked
  - Differences can arise by mistakes or limitations of the problem/data
  - E.g., the model works well for average behavior but fails to predict rare
    values

* Bayesian Workflow Using PPC

1. You have data from a process
   - True distribution unknown / unknowable
2. Sample
   - Get finite sample $y$ through sampling
   - E.g., experiment, survey, simulation
3. Inference
   - Build probabilistic model using prior $\Pr(\theta)$ and likelihood
     $\Pr(y | \theta)$ to get posterior distribution $\Pr(\theta | y)$
   - Posterior distribution: distribution of model parameters $\theta$ given data
4. Predictive distribution
   - Compute predictions from posterior distribution (i.e., posterior predictive
     distribution)
   - Posterior predictive distribution: distribution of predicted samples
     averaged over posterior distribution
5. Validation
   - Validate model by comparing original samples vs predicted samples

### Robust Inference

* Chemical Shift Example: PPC
::: columns
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_pymc_solution3.png)
::::
:::: {.column width=40%}
- **Is the PPC model good?**
- No
  - Posterior mean is more to the right than data
  - Posterior std dev is larger
::::
:::

* Chemical Shift: Model Critique
::: columns
:::: {.column width=40%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_pymc_solution3.png)
::::
:::: {.column width=55%}
- **Problem**
  - Two data points on the tails of the distribution
  - The normal distribution is "surprised" by these points and "reacts" by
    adjusting the mean towards them and increasing the standard deviation
::::
:::

- **Solution**
  - Declare points as outliers and discard
    - E.g., equipment malfunction (need evidence)
  - Change the model

- Bayesians prefer to encode assumptions into the model (e.g., priors,
  likelihoods)
  - Rather than ad-hoc heuristics (e.g., outlier removal rules)

* Student's t-distribution: Recap
- Student's t-distribution has 3 params:
  1. Mean $\mu$
     - It doesn't always exist
  2. Scale $\sigma$
     - Similar to std dev, but it doesn't always exist
  3. Degrees of freedom $\nu \in [0, \infty]$
     - Aka "normality parameter", since it controls how "normal" is the
       distribution
     - With $\nu=1$: heavy tails and no mean (Cauchy)
     - With $\nu \to \infty$ we recover the Gaussian
- Heavy tails (high kurtosis) means _"values are more likely to be far from the
  mean compared to a Normal"_

![](msml610/lectures_source/figures/Lesson07_Student-t.png){ height=30%}

* Chemical Shift: Use Student's t-dist (1/3)
::: columns
:::: column
- Use Student's t-distribution model instead of Normal

\begin{equation*}
  \begin{cases}
  \mu \sim U(l, h) \\
  \sigma \sim HalfNornal(0, \sigma) \\
  \nu \sim Exp(\lambda) \\
  y \sim StudentT(\mu, \sigma, \nu) \\
  \end{cases}
\end{equation*}
::::
:::: column
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_robust_model.png)
::::
:::

* Chemical Shift: Use Student's t-dist (2/3)
::: columns
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_robust_model2.png)
::::
:::: {.column width=35%}
- Outliers decrease $\nu$ (less Gaussian) instead of increasing mean and standard
  deviation
  - $\mu$ similar to Gaussian estimate
  - $\sigma$ smaller
  - $\nu \approx 5$ (not very Gaussian)
- Estimation more robust; outliers have less effect
::::
:::

* Chemical Shift: Use Student's t-dist (3/3)
::: columns
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_robust_model3.png)
::::
:::: {.column width=35%}
- PPC (posterior predictive check) fits better than Normal model
- Plot is "hairy" because KDE is estimated only in data interval and 0 outside
::::
:::

# #############################################################################
# Groups Comparison
# #############################################################################

* Group Comparison
- **Group comparison** tests for statistically significant results between
  "treatment" and "control group"

- E.g., ![](emoji/pushpin_tack.png){ width=12px }
  - How well do patients respond to a new drug vs a placebo?
  - Is there a reduction in car accidents after new traffic regulation?
  - Does college student performance improve without cellphones at school?

- **Effect size** quantifies the difference between two groups
  - Moves from "does it work?" (hypothesis testing) to "how well does it work?"
    (estimate effect size)

* Bogus Control Groups
- When something is claimed to be harder/better/faster/stronger, ask for the
  baseline used for comparison
  - E.g.,
    - Sell sugary yogurts to boost the immune system by comparing it to using
      milk
    - A better control group would be a less sugary yogurt

- **Placebo** is a psychological phenomenon where a patient experiences
  improvements after receiving an inactive treatment
  - Using a placebo is better than "no treatment"
  - Shows difficulty in accounting for all factors in an experiment

* Group Comparison Bayesian-Style
- **Frequentist approach**
  - Compare p-value of difference of means in each group

- **Bayesian approach**
  - Compare posterior distribution of means between groups using:
    - Plot of posterior
    - Cohen's d
    - Probability of superiority

* Sample Size Effect
- **Sample size effect** is the impact of the number of observations on
  statistical results (e.g., p-values, confidence intervals)
  - Small sample: Large mean difference might not be statistically significant
    (low p-value)
  - Large sample: Tiny mean difference can be highly significant (small p-value)
    but meaningless
  - E.g., Cohen's d

* Cohen's d
- **Cohen's d** is the difference of means relative to pooled standard deviation
  $$
  \frac{\mu_2 - \mu_1}{\sqrt{(\sigma_1^2 + \sigma_2^2) / 2}}
  $$
  - Normalizes effect by variability for pooled std dev
  - Bayesian analysis estimates actual std dev
- Variability of each group normalizes mean difference
  - Similar to a Z-score, number of std dev values differ
- Compute posterior distribution of means and std
- Compute distribution of Cohen's d or use formula

* Probability of Superiority
- = probability that a data point taken randomly from one group is larger than a
  random point from the other group

- We can compute the

// TODO: Finish

// 3, Hierarchical models

# #############################################################################
# Hierarchical Models
# #############################################################################

* Hierarchical Models
- Aka "multilevel", "nested", "mixed-effects" models

- **Observation**: Data points share common structure, but also have variations
  - Group data
    - E.g., sales in cities: each city is a market, with common trends
  - Hierarchical structure
    - E.g., students in a school: each student is different, with common
      educational factors
  - Repeated measurements on same objects

- **Approach**: ![](emoji/lightbulb.png){ width=14px }
  - Model shares information between groups, but it allows differences
  - Parameters of prior distributions have a prior distribution, aka
    "hyper-priors"

* Hierarchical Models: Examples
- Many data structures lend themselves to hierarchical descriptions

- E.g.,
  - Medical research:
    - Estimate drug effectiveness in treating a disease
    - Categorize patients by demographics, disease severity
    - Estimate cure probability for each subgroup
  - Market research
    - Understand consumer purchasing behavior
    - Categorize consumers by age, gender, income, education

* Unpooled, Pooled, Hierarchical Models
- **Unpooled**
  - Groups have different priors
- **Pooled**
  - Groups have the same priors
- **Hierarchical**
  - Groups have different priors which come from a common prior

![](msml610/lectures_source/figures/Lesson07_Pooled_unpooled_hierarchical_models.png){ width=80% }

// TODO(gp): Convert it into graphviz

// ## 3.2, Hierarchical shifts

* Hierarchical Models: Chemical Shift
- Proteins are made of 20 amino acids
  - Study proteins with nuclear magnetic resonance
  - Measure "chemical shift"

- The data looks like:

::: columns
:::: {.column width=40%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_hierarchical1.png)
::::
:::: {.column width=55%}
- `ID`: Code of the protein
- `aa`: Name of the amino acid
- `theo`: Theoretical values of chemical shift
- `exp`: Experimental value
- `diff`: Difference between theoretical and experimental value
::::
:::

* Hierarchical Models: Chemical Shift
- Experimental measures of chemical shifts vs theoretical values
- Evaluate model using different modeling styles
1. **Unpooled**
   - Fit 20 Gaussians for 20 amino acids
   - Detailed analysis, less accuracy
2. **Pooled**
   - Compute difference between estimates and measures, fit Gaussian
   - More accurate estimates, lose amino acid information
3. **Hierarchical**
   - Model groups assuming common population

* Chemical Shift: Unpooled Model

::: columns
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_hierarchical2.png)
::::
:::: {.column width=35%}
- Model each group independently
- Use same model structure to compare groups
::::
:::

* Chemical Shift: Hierarchical Model
::: columns
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_hierarchical3.png)
::::
:::: {.column width=35%}
- Add two hyperpriors:
  - One for mean of $\mu$
  - One for standard deviation of $\mu$
- Assume same variance for all groups
  - Modeling choice
  - Option to add hyperpriors for $\sigma$
- Intermediate situation between single group and 20 separate groups
::::
:::

* Chemical Shift: Results
::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Chemical_shift_hierarchical4.png)
::::
:::: {.column width=45%}
- Compare estimates of two models
- 20 groups, each model has 4 estimated variable
  - Plot 94% credible intervals
  - Black vertical line: global mean (hierarchical model)
  - Blue (hierarchical) means pulled towards mean compared to orange
    (non-hierarchical)
  - "Shrinkage" occurs
::::
:::

* Shrinkage
- Hierarchical models **shrink parameters towards a common mean**, as groups
  share information through the hyper-prior
  - Model groups as neither independent nor a single group, but in between
  - Less responsive to extreme values in individual groups
  - Improves estimation for small groups using data from others
- **Amount of shrinkage** depends on data:
  - Groups with more data influence estimates more
  - Similar groups reinforce common estimation
- **Result**: inference is more stable

* You Need to Know When to Stop
- Create hierarchical models with as many levels as you want
- More levels:
  - Don't improve inference quality
  - Complicate interpretation
- Goal:
  - Leverage data structure
  - Add as many degrees as freedom as needed, but not more than what is warranted
    (Occam's razor)

// 4, Modeling with lines

# ##############################################################################
# Simple Linear Model
# ##############################################################################

* Linear Model
- Many problems can be stated as:
  - $X$ and $Y$: uni-dimensional continuous RVs
  - Dataset of paired observations $\{(x_1, y_1), ..., (x_n, y_n)\}$
  - $X$: independent variable
  - Model/predict dependent variable $Y$
  - Assume a linear relationship between $Y$ and $X$

- E.g.,:
  - Average temperature vs Nobel laureates in a country
  - Sugar intake vs Blood glucose
  - Years of education vs Annual income
  - Advertising spend vs Sales
  - Study hours vs Exam score
  - Coffee consumption vs Productivity

* Linear Model: Frequentist Approach
- A **linear model** is described by:
  $$
  y = \alpha + \beta x
  $$
- **Frequentist approach**:
  - Find parameters $\alpha, \beta$ using least square fitting
    - Minimize average quadratic error between observed $y$ and predicted
      $\hat{y}$
  - Point-estimate from least squares corresponds to maximum a-posteriori with
    flat priors

* Linear Model: Bayesian Approach
- A **linear model** is described by:
  $$
  y = \alpha + \beta x
  $$
- **Bayesian approach assumes**:
  - Data is Gaussian with mean $\alpha + \beta x$ and standard deviation
    $\sigma$: $y \sim N(\mu=\alpha + \beta x, \sigma)$
  - $\alpha, \beta, \sigma$ are independent
  - Priors:
    \begin{equation*}
      \begin{cases}
      \alpha \sim Normal(\mu_\alpha, \sigma_\alpha) \\
      \beta \sim Normal(\mu_\beta, \sigma_\beta) \\
      \sigma \sim HalfNormal(0, \sigma_\epsilon) \\
      \end{cases}
    \end{equation*}
- Use **vague priors**:
  - Prior of intercept $\alpha$ often centered around $0$
  - Info on sign of $\beta$ sometimes available
  - Half-Cauchy / exponential distribution for $\sigma$
  - Uniform prior if parameter has hard boundaries

// ## Linear model: synthetic example

* Linear Model: Synthetic Example
::: columns
:::: {.column width=35%}
- Generate random data from ground truth
  - $\alpha = 2.5$
  - $\beta = 0.9$
  - Add noise
::::
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Linear_regression_synthetic_example1.png)
::::
:::

* Linear Model: Synthetic Example
::: columns
:::: {.column width=35%}
- Create linear model in PyMC
- Use vague priors
  - Prior of intercept $\alpha$ and $\beta$ centered around $0$
  - Half-Cauchy distribution for $\sigma$

::::
:::: {.column width=60%}
![](msml610/lectures_source/figures/Lesson07_Linear_regression_synthetic_example2.png)
::::
:::

* Linear Model: Synthetic Example
::: columns
:::: {.column width=35%}
- Run the sampler
- Ground truth
  - $\alpha = 2.5$
  - $\beta = 0.9$
- Recovered values
  - $\alpha = 2.12$
  - $\beta = 0.95$

::::
:::: {.column width=70%}
![](msml610/lectures_source/figures/Lesson07_Linear_regression_synthetic_example3.png)
::::
:::

// ## Linear model: bike rental example

* Linear Model: Bike Rental Example

- Model relationship between temperature $X$ and number of bikes rented $Y$

![](msml610/lectures_source/figures/Lesson07_Bike_rental_data.png){ width=80% }

- Use intermediate variable $\mu = \alpha + \beta X$, mean number of bikes
  rented for temperature $X$
  $$
  Y \sim N(\mu, \sigma)
  $$

* Linear Model: Bike Rental Example

::: columns
:::: {.column width=45%}

- Fit model: $\mu = 69 + 7.9 X$

- Interpreting the model
  - For temperature 0 expected rented bikes = 69
  - Each degree increase: expected value increases by 7.9

- Parameters have uncertainty
  - Posterior accounts for combined uncertainty
  - Bands represent quantiles [0.25, 0.75] and [0.03, 0.97] of prediction

::::
:::: {.column width=50%}

![](msml610/lectures_source/figures/Lesson07_Bike_rental_data_2.png)
![](msml610/lectures_source/figures/Lesson07_Bike_rental_data_3.png)

::::
:::

- **Do you see any problem in the model?** ![](emoji/puzzle.png){ width=14px }

* Linear Model: Bike Rental Example (Criticism)

- **Problems**
  - Model outputs negative bike numbers
  - Model predicts real numbers, but count is discrete

- **Root cause**: Not surprising since using Normal likelihood:
  - Extends to negative numbers
  - Is continuous

- **Solutions**:
  - Clip predictions below 0 and discretize output (hack)
  - Use model defined for positive numbers only

* Generalized Liner Model (GLM)
- Generalization of linear model using different distributions for likelihood:
  \begin{equation*}
    \begin{cases}
    \alpha \sim prior \\
    \beta \sim prior \\
    \mu = \alpha + \beta X \\
    \theta \sim prior \\
    Y \sim \phi(f(\mu), \theta) \\
    \end{cases}
  \end{equation*}
  where:
  - $\phi$: arbitrary distribution
    - E.g., Normal, Student's t, negative binomial
  - $\theta$: auxiliary parameter for $\phi$
    - E.g., $\sigma$ for Normal
  - $f()$: "inverse link function" transforming $\mu$ from the real line to
    domain of $\phi$

// ## 4.4 Counting bikes

* Count Data
- **Count data** = when the RV is a discrete number and bounded at 0
  - E.g., the number of rented bikes
- If the number is large, we can use a continuous distribution
  - E.g., Gaussian
- Other times, it's modeled as discrete
  - E.g., Poisson, negative binomial

* Poisson Distribution

::: columns
:::: {.column width=50%}
- **Poisson distribution**
  - Models number of events in a fixed interval (e.g., time, space)
  - Assumes events happen independently at a constant average rate

- **E.g.,**
  - Call centers: number of customers per hour
  - Natural events: number of earthquakes in a region over time
  - Traffic flow: number of cars through a toll booth per day
  - Biology: count mutations in a DNA segment over time

- **Cons**:
  - Assumes mean equals variance (can't model "overdispersion")
::::
:::: {.column width=50%}

![](msml610/lectures_source/figures/Lesson07_Poisson_PMF.png)

::::
:::

* Negative Binomial Distribution
::: columns
:::: {.column width=50%}
- **Negative binomial distribution**
  - Models failures/trials to achieve fixed number of successes in IID Bernoulli
    trials
  - Generalizes geometric distribution, which models number of trials to achieve
    first success
  - Models overdispersion (i.e., mean << variance)
- **E.g.,**
  - Customer service: unsuccessful interactions before success
  - Sports: games lost before winning a fixed number of games
::::
:::: {.column width=50%}

![](msml610/lectures_source/figures/Lesson07_Neg_binomial_PMF.png)

::::
:::

* Overdispersion
- **Overdispersion** occurs when variance of count data is much larger (e.g.,
  15-20x) than mean
- **E.g.,**
  - Epidemiology: when modeling disease outbreak, number of new infections on a
    given day might fluctuate widely
  - Customer service: large variation of number of daily complaints

- **How to model it?**
  - Poisson distribution:
    - Mean and variance equal ![](emoji/wrong.png){ width=12px }
  - Negative binomial:
    - Second parameter controls variance ![](emoji/check_mark.png){ width=12px }
  - **Model using Normal**:
    - Mismatch when predicting negative rented bikes
    - Poor fit even on positive side
  - **Model using Negative Binomial**:
    - Better fit, though not perfect
    - Right tail predictions differ, but high demand probability is low
    - Overall better than Normal model

// ## 4.5, Robust regression

* Robust Regression
::: columns
:::: {.column width=40%}
- Outliers pull regression line away from bulk of data

::::
:::: {.column width=55%}
![](msml610/lectures_source/figures/Lesson07_Non_robust_regression1.png)
::::
:::

- Student's t-distribution
  - Has heavier tails than Normal
  - Gives less importance to outliers

::: columns
:::: {.column width=45%}

//![](msml610/lectures_source/figures/Lesson07_Robust_regression_code.png)
![](msml610/lectures_source/figures/Lesson07_Robust_regression_model.png)

::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/Lesson07_Non_robust_regression2.png)

::::
:::

// ## 4.6, Logistic regression

## #############################################################################
## Logistic Regression
## #############################################################################

* Logistic Regression
- Logistic regression model
  - Is a generalized linear model
  - Models the response variable as binary
    - E.g., ham/spam, safe/unsafe, cloudy/sunny, hotdog/not hotdog

- The logistic model is:
  \begin{equation*}
    \begin{cases}
    \theta = logit(\alpha + \beta x) \\
    y \sim Bernoulli(\theta) \\
    \end{cases}
  \end{equation*}

::: columns
:::: {.column width=40%}

- Logistic function (aka sigmoid)

  $$
  logit(z) = \frac{1}{1 + \exp^{-z}}
  $$
  - Converts real numbers from $\theta$ to [0, 1] for the Bernoulli distribution

::::
:::: {.column width=55%}

```tikz
\begin{axis}[
    width=12cm, height=7cm,
    xmin=-6, xmax=6,
    ymin=-0.05, ymax=1.05,
    axis lines=left,
    xlabel={$x$},
    ylabel={$P(y=1 \mid x)$},
    domain=-6:6,
    samples=400,
    grid=both,
    minor grid style={gray!15},
    major grid style={gray!25},
    legend style={draw=none, fill=none, at={(0.02,0.98)}, anchor=north west, font=\small},
    tick label style={font=\small},
    label style={font=\small},
  ]

  % --- logistic curve: P(y=1|x) = 1/(1 + exp(-(a x + b)))
  % adjust a (slope) and b (intercept) to taste:
  \def\a{1.2}
  \def\b{-0.5}
  \addplot[very thick] {1/(1 + exp(-(\a*x + \b)))}; 

  % --- decision threshold at 0.5
  \addplot[densely dashed] coordinates {(-6,0.5) (6,0.5)};
  \addlegendentry{Threshold $=0.5$}

  % --- implied decision boundary x* where a x + b = 0  =>  x* = -b/a
  \pgfmathsetmacro{\xb}{-(\b)/(\a)}
  \addplot[densely dotted] coordinates {(\xb, -0.05) (\xb, 1.05)};
  \addlegendentry{Boundary $x^\star=-b/a$}

  % --- optional: annotate boundary
  \node[anchor=north east, font=\small] at (axis cs:\xb,0.0) {$x^\star$};

\end{axis}
```
::::
:::

* Iris Dataset
- Classical dataset of measurements from flowers from 3 closely related species
  of Iris setosa, virginica, and versicolor
  - E.g., we want to predict the probability of a flower being `setosa` from the
    `sepal_length`

![](msml610/lectures_source/figures/Lesson07_Logistic_regression_df.png)

* Classification with Logistic Regression

- **Logistic regression**:
  - Computes the probability that the output is a certain value
  - Models $\theta = \Pr(Y=1 | X)$
  - Classifies the output using a decision rule, e.g.,
    $$
    \Pr(Y = \texttt{versicolor} | \texttt{sepal\_length}) > 0.5
    $$

- "Classification with logistic regression" might seem a **misnomer**
  - **Regression** predicts a continuous variable given input variables
  - **Classification** predicts a discrete variable given input variables
  - Is a "regression" since it computes the probability that the output is a
    certain value

* Boundary Decision for a Classifier
- **Boundary Decision** $\delta$ for a classifier = values of independent
  variables making probability equal to 0.5

- For logistic regression $\delta$:
    \begin{align*}
    & 0.5 = logit(\alpha + \beta \delta) \\
    & 0 = \alpha + \beta \delta\\
    & \delta = - \frac{\alpha}{\beta} \\
    \end{align*}
  - Decision boundary has uncertainty due to uncertainty in $\alpha$ and $\beta$

- The probability threshold $0.5$ chosen for equal misclassification risk
  - Misclassification cost may not be symmetrical
  - E.g., minimize false negatives ("patient has disease, not predicted") or
    false positives ("patient doesn't have disease, predicted")

* Odds
- The **odds** of event $y=1$ is:
  $$
  \text{odds} \defeq \frac{\Pr(y=1)}{1 - \Pr(y=1)}
  $$
  - Ratio between favorable vs unfavorable events

- Transformation exists between probability, odds, and log-odds

- More intuitive than probability in "gambling"
  - E.g., odds of getting a 2 rolling a fair die are
    $\frac{1/6}{5/6} = \frac{1}{5} = 0.2$
  - One favorable event for 5 unfavorable events

- Interpreting **logistic regression in terms of odds**:
  - Since $\theta = logit(\alpha + \beta x)$ and $\theta = \Pr(y = 1)$, we get:
    $$
    \alpha + \beta x = \log ( \frac{\Pr(y=1)}{1 - \Pr(y=1)} )
    $$
  - Logistic regression models log-odds as linear regression
  - $\beta$ is the increase of log-odds for a unit change of $x$

* Classification with Logistic Regression: Bayesian

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Logistic_regression_code.png)

::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Logistic_regression_model.png){ height=50% }

::::
:::

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Logistic_regression_result.png)

::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Logistic_regression_result2.png)

::::
:::

* Heteroskedasticity
- **Heteroskedasticity** = when variance of errors is not constant across
  observations
  - E.g., variance can be a linear function of the dependent variable

- **Example**:
  - Variance of baby height as a function of age is heteroskedastic
  - $\sigma$ is a linear function of the predictor variable
  - Mean $\mu$ is square root of a linear model

![](msml610/lectures_source/figures/Lesson07_Variable_variance_data.png)

* Heteroskedasticity: Bayesian Model
::: columns
:::: {.column width=50%}

![](msml610/lectures_source/figures/Lesson07_Variable_variance_code.png)

::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Variable_variance_model.png)

::::
:::

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Variable_variance_result.png)

::::
:::: {.column width=50%}

::::
:::

//## Hierarchical linear regression
//
//// TODO: Finish
//
//* Hierarchical linear regression
//- Hierarchical models are a powerful concept that allows us to model complex data
//  structures
//- We can do inference at / above the group level at the same time
//- Groups can share information by using hyper-priors, which provides shrinkage
//  and regularizes estimates
//
//- E.g., hierarchical linear regression models
//
//* Divergences after tuning
//- Sometimes PyMC reports "divergences after tuning" (e.g., this is the case with
//  linear models)
//  - Samples generated by PyMC may not be trustworthy
//
//- Solutions
//  1) You can increase `target_accept` in `pm.sample()`
//  2) Re-parametrize model = re-write model in a different way to help the sampler
//     (e.g., remove the divergences) or the model's interpretability
//
//* Centered vs non-centered hierarchical models
//- Hierarchical centered
//  - We estimate the parameters for the individual groups
//- Hierarchical non-centered
//  - Estimate common parameters for all groups and then the deflection for each
//    group
//  - The information is represented in the same way

# Multiple linear regression

* Multiple Linear Regression
- In prediction problems, several independent variables are common 
  - E.g., student's grades = f(family income, mother's education, ...)

- **Problem formulation**
  - $k$ independent variables
  - $N$ observations
  - Find a hyperplane of dimension $k$ to explain data
  $$
  \mu = \alpha + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k
  $$
  - Same as polynomial regressions but with independent variables

* Multiple Regression: Synthetic Example 1/2

- Generate random data

::: columns
:::: {.column width=40%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression1.png)
::::
:::: {.column width=55%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression2.png)
::::
:::

- Create PyMC model

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model_code.png)
::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model.png)
::::
:::

* Multiple Regression: Synthetic Example 2/2

- Solve model

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_results1.png)
::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_results2.png)
::::
:::

* Multiple Regression: Rented Bike Example 1/2

- Assumption: number of bike rented is function of temperature and hour of the
  day

- Create model

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model_RentedBikes_model_code.png)
::::
:::: {.column width=45%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model_RentedBikes_model.png)
::::
:::

* Multiple Regression: Rented Bike Example 2/2

- Solve model

::: columns
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model_RentedBikes_model_trace.png)

::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07_Multiple_linear_regression_model_RentedBikes_model_results.png)
::::
:::

// 5, Comparing models

# ##############################################################################
# Comparing Models
# ##############################################################################

* Models as Maps of the Real World
- Often you need to compare models to understand which one is **"better"**

- Models are a **map, not a copy** of the real world
  - _"All models are wrong, but some are useful"_ (Box, 1976)
    - All models are wrong since they aren't the actual territory
    - Some models describe a problem better than others

- Models have a **purpose**
  - Are approximations to understand a problem
  - A model can't reproduce all aspects equally well
  - Different models capture different data aspects

// ## 5.1., Posterior predictive checks

### ############################################################################
### Posterior Predictive Checks
### ############################################################################

* Posterior Predictive Checks

::: columns
:::: {.column width=50%}
- Goal of PPC:
  - Evaluate model's data explanation
  - Understand model limitations
  - Improve model

- Given data from parabola + noise:
  - Fit with linear model
  - Fit with quadratic model
  - Compare predicted (posterior) vs observed data

::::
:::: {.column width=50%}

![](msml610/lectures_source/figures/Lesson07.Comparing_models.data.png)

![](msml610/lectures_source/figures/Lesson07.Comparing_models.model_code.png)

::::
:::

* Posterior Predictive Checks

::: columns
:::: {.column width=50%}
- Compare KDE of observed and predicted data:
  - Linear model KDE doesn't match
  - Quadratic model KDE matches better
  - High uncertainty in both models, especially at tails

- Compare mean / interquartile range for data vs model
  - Plot dispersion of mean and IQR for models vs data
  - Data set provides a single point
  - Posterior provides a distribution

- Statistics "orthogonal" to model's focus are more informative

::::
:::: {.column width=50%}
![](msml610/lectures_source/figures/Lesson07.Comparing_models.model_fit.png)

![](msml610/lectures_source/figures/Lesson07.Comparing_models.lin_model_PPC.png)
![](msml610/lectures_source/figures/Lesson07.Comparing_models.quadr_model_PPC.png)
::::
:::

* Bayesian P-Value for a Statistic
- A Bayesian p-value summarizes the comparison between simulated and observed
  data

- **Procedure**
  - Given the posterior predictive $\tilde{Y}$
  - Choose a summary statistic $T$ (E.g., mean, median, standard deviation)
  - Compute $T$ for:
    - The observed data $T_{obs}$
    - The simulated data $T_{sim}$ from the posterior predictive
  - Compute the Bayesian p-value as the portion of simulated datasets where the
    test statistic is smaller than the observed data:
    $$
    \text{Bayesian p-value} \defeq \Pr(T_{sim} \ge T_{obs} | \tilde{Y})
    $$
  - If observed values agree with predicted ones, the value should be around 0.5

* Bayesian P-Value for Entire Distribution
- Instead of using a summary statistic, one can compute "the probability of
  predicting a lower or equal value for each observed value"

- If the model is well calibrated, it captures all observations equally well,
  the probability should be the same for all observed values
  - The output should be a uniform distribution

// TODO: Compute Bayesian p-value for parabola vs linear fit

* Bayesian P-Value: Example
- Study the height of people in a population

- **Fit the Bayesian model**
  - Assume a normal distribution with unknown mean and variance
  - Collect observed data of heights (e.g., 100 people)
  - Specify a prior distribution for mean and variance
  - Combine observed data with prior to obtain a posterior distribution of mean
    and variance of population height

- **Compute Bayesian p-value**
  - From posterior distribution:
    - Generate new simulated datasets
    - For each dataset, compute mean height
  - Use test statistic $T$, as the difference between the mean of the replicated
    dataset and the observed mean
  - Compute Bayesian p-value: the proportion of replicated datasets where the
    test statistic is >= test statistic for observed data
    - A value close to 0.5 means the observed data is covered by the model
    - A value close to 0 or 1 indicates a poor fit

* Bayesian vs Frequentist P-Value
- **Frequentist p-value** is the probability of getting observed data as or more
  extreme, assuming the null hypothesis is true

- **Bayesian p-value** is the probability that simulated data from the model
  (i.e., posterior predictive check) is as or more extreme than the observed
  data

- P-value measures inconsistency between observed data and:
  - A null hypothesis (frequentist approach)
  - Model (Bayesian approach)

- Does p-value incorporate uncertainty?
  - (frequentist) No: use single point estimates
  - (Bayesian) Yes, incorporate uncertainty of parameter estimates

// ## 5.2, The balance between simplicity and accuracy

## #############################################################################
## The Balance Between Simplicity and Accuracy
## #############################################################################

* Occam's Razor
- _"If you have **equivalent** explanations for the same phenomenon, you should
  choose the **simpler** one"_
  - Quality of explanation $\approx$ accuracy
  - Simpler $\approx$ number of model parameters

- Ideally we should balance complexity and accuracy in a quantitative way

- Complexity vs accuracy
  - Increasing model complexity (e.g., number of model parameters) is
    accompanied by increasing in-sample accuracy, but not necessarily
    out-of-sample accuracy
  - The complex model:
    - Did not "learn" from the data but just "memorize" it
    - Do a bad job generalizing to predict potentially observable data

* Overfitting and Underfitting
- A model is **overfit** when it has many parameters, fitting the training data
  well but unseen data poorly
  - Overfitting in terms of signal/noise:
    - Each dataset has "signal" and "noise"
    - We want the model to learn the signal
    - A model overfits when it learns the noise, obscuring the signal

- A model is **underfit** when it has few parameters, fitting the dataset poorly
  - An underfit model doesn't learn the signal well
  - E.g., a constant fits a dataset, only learning the mean

// ## 5.3, Measures of predictive accuracy

* Bias-Variance Trade-Off
- A model has **high bias** when it has low ability to accommodate the data
  (i.e., underfitting)
  - E.g., a polynomial of degree 0

- A model has **high variance** when it has high capacity and it is sensitive to
  details in the data, capturing noise (i.e., overfitting)
  - E.g., a polynomial of degree 5

- Trade-off between bias and variance
  - Goal: balance simplicity and goodness of fit
  - Aim for a model that "fits the data right," avoiding overfitting or
    underfitting

## #############################################################################
## Measures of Predictive Accuracy
## #############################################################################

* Accuracy Measures
- **In-sample accuracy** is measured on the data used to fit a model
- **Out-of-sample accuracy** is measured on data not used to fit a model
  - Aka "predictive accuracy"

- In-sample accuracy > out-of-sample accuracy

- There is a trade-off between how much data is used for training and for
  evaluating true accuracy

// ### 5.3.1, Information criteria

### ############################################################################
### Information Criteria
### ############################################################################

* Information Criteria: Intuition
- Information criteria are tools to compare models in terms of fitting the data
  taking into account their complexity through a penalization term
  - Out-of-sample accuracy $\approx$ in-sample accuracy + a term penalizing
    model complexity

* Model Parameters for Bayesian vs Non-Bayesian Set-Up
- Model parameters $\theta$ are:
  - A point estimate (frequentist)
  - A distribution estimated from the posterior (Bayesian)

* Squared Error Metric
- Squared error between the data and the predictions from the model
  $$
  \frac{1}{N} \sum_i (y_i - \EE[y_i | \theta])^2
  $$
  where $\EE[y_i | \theta]$ is the predicted value given the parameters
- Squaring errors:
  - Ensures that errors do not cancel out
  - Emphasizes large errors (vs absolute values)

* Log-Likelihood
- In a probabilistic set-up, log-likelihood is more natural
- **Log-likelihood** is defined as:

  $$
  \sum_i \log \Pr(y_i | \theta)
  $$

- Deviance is defined as:

  $$
  -2 \sum_i \log \Pr(y_i | \theta)
  $$

* Maximum Likelihood Estimation (MLE)
- MLE finds the parameter values that make the observed data most probable
  - Denoted by $\hat{\theta}_{MLE}$
  - It's a point not a distribution

- Procedure:
  - Given the data $x_1, x_2, ..., x_n$
  - Assume it comes from a distribution with an unknown parameter $\theta$
  - Pick the value of $\theta$ that makes the data most likely given a likelihood
    function
//    $$
//    \left\{
//        \begin{array}{l}
//        \end{array}
//    \right
//    $$
  \begin{equation*}
    \begin{cases}
      L(\theta) = \log \Pr(x_1, x_2, ..., x_n | \theta) \\
      \hat{\theta}_{MLE} = \argmax_{\theta} L(\theta) \\
    \end{cases}
  \end{equation*}

- In Bayesian terms, MLE is equivalent to the mode of $\theta$ using flat priors
  - Aka MAP (maximum a posteriori)

* Akaike Information Criterion (AIC)
- AIC is defined as

  $$
  AIC = -2 \sum \log \Pr(y_i | \hat{\theta}_{MLE}) + 2 \text{num}_{params}
  $$

  where:
  - $\hat{\theta}_{MLE}$ is the maximum likelihood estimation of $\theta$
  - $\text{num}_{params}$ is the number of parameters

- **Interpretation**:
  - The first term measures how well the model fits the data
  - The second term penalizes complex models

- **Cons**:
  - Discard information about uncertainty of posterior estimation
  - MLE assumes flat priors (vs informative and weakly informative priors)
  - Number of parameters is not always a good measure of complexity
    - E.g., in hierarchical models the effective number of params is smaller

* Bayesian Information Criteria
- Widely Applicable Information Criteria (WAIC)
  - Bayesian version of AIC
  - It has two terms:
    - One that measures how good the fit is
    - One that penalizes complex models
  - WAIC uses the posterior distribution to estimate both terms `
- Bayesian Information Criteria (BIC)
  - It is not fully Bayesian
    - Like AIC, it assumes flat priors and uses MLE

// ### 5.3.2, Cross-validation

### ############################################################################
### Cross-Validation
### ############################################################################

* Cross-Validation
- Cross-validation (CV)
  - Simple and effective solution to use all data to compare models
  - **Procedure**
    - Partition data into $K$ portions of equal size and similar statistics
    - Use $K-1$ partitions to train the model and the remaining partition to
      test it
    - Repeat $K$ times
    - Average the results

- Leave-one-out cross-validation (LOO-CV)
  - **Procedure**:
    - The model is fit for all data, excluding one observation
    - The model's predictive accuracy is tested on the left out observation
    - Repeat the process for all observations and average
  - **Cons**
    - It is very computationally expensive since one needs to refit the model

- How to adapt cross-validation to a Bayesian approach?
  - CV and LOO require multiple model fits and fitting a Bayesian model is very
    expensive
  - Yes! There is a way to approximate using a single fit to the data

// TODO: add picture

* ELPD with LOO-CV
- We want to compute $ELPD_{LOO-CV}$ where:
  - "Expected Log-Pointwise predictive Density" (ELPD)
    - It should be ELPPD and not ELPD!
  - We use "Leave-One-Out Cross-Validation" (LOO-CV) to compute it

- The definition of ELPD with LOO-CV is:

  $$
  ELPD_{LOO-CV} =
    \red{\sum_{i=1}^n} \log
    % Need to avoid the `text` inside `\textcolor`.
    \textcolor{violet}{\int}
    \teal{p(y_i | \theta)}
    \blue{(\theta | y_{-i})}
    \textcolor{violet}{d\theta}
  $$
  - Where:
    - \blue{Fit a model using all the data without $y_{-i}$}
    - \teal{Predict the unseen $y_i$ with the model}
    - \violet{Integrate on all the posterior values}
    - \red{Repeat for all the points}

- How to compute it efficiently?
  - Use "Pareto smooth importance sampling leave-one-out cross-validation"

* Pointwise Predictive Density (PPD)
- The **pointwise predictive density** (or probability) for a given data point
  $y_i$ is defined as the posterior predictive probability, given the rest of
  the data

  $$
  PPD
  \defeq \Pr(y_i | data - \{i\})
  = \textcolor{blue}{\int} \red{p(y_i | \theta)} \green{p(\theta | y_{-i})} \textcolor{blue}{d\theta}
  $$

  where:
  - $y_i$ is the observed data point
  - \red{$p(y_i | \theta)$} is the \red{likelihood} of the data point $y_i$
    given the model parameters $\theta$
  - \green{$p(\theta | y_{-i})$} is the \green{posterior distribution} of the
    model parameters given the rest of the observed data
  - The \blue{integral} averages over the posterior distribution of $\theta$,
    capturing the uncertainty about the model parameters

- **Interpretation**
  - PPD measures how well a model, training on the data excluding $y_i$,
    predicts $y_i$
  - It's like cross-validation but using the Bayesian concept of averaging over
    the distribution of the parameters

* Expected Log Pointwise Predictive Density
- The ELPD is the \red{average} over unseen points of the \green{log} \blue{PPD}

  $$
  ELPD = \textcolor{red}{\sum_{i=1}^n} \textcolor{green}{\log}
  \textcolor{blue}{\int p(y_i | \theta_{-i}) p(\theta_{-i} | y_{-i}) d\theta}
  $$

- **Interpretation**
  - It can be used to determine which model generalizes better to new data
  - ELPD measures the predictive accuracy of a Bayesian model on unseen data
  - Train on $y_{-i}$, i.e., all data excluding $y_i$
  - Test on $y_i$

* Approximating PPD
- Calculating analytically the pointwise posterior density integral

  $$
  PPD = \int p(y_i | \theta) p(\theta | y_{-i}) d\theta
  $$

  is difficult
  - The posterior $p(\theta | y_{-i})$ rarely has a closed form
  - The integral on $\theta$ is on a high-dimensional space

- It can be approximated numerically given posterior samples $s$ of the model
  parameters $\theta^{(s)}$

  $$
  PPD \approx \frac{1}{S} \sum_s p(y_i | \theta^{(s)}_{-i})
  $$
  - Suppose we already have posterior samples $\theta^{(s)} \sim p(\theta | y)$
    from the full dataset

* PSIS-LOO-CV
- Compute the Expected Log Pointwise Predictive Density (ELPD) using
  Leave-One-Out Cross-Validation (LOO-CV):

  $$
  ELPD_{LOO-CV} \defeq \sum_i \log \int p(y_i | \theta) p(\theta | y_{-i}) d\theta
  $$

- **Problem**: Train once per point

- **Solution**:
  - Pareto-Smoothed Importance Sampling (PSIS) Leave-One-Out Cross-Validation
    (LOO-CV) estimates the formula without refitting the model for every point
  - **Importance sampling**:
    - Use the full dataset to approximate the posterior distribution when a
      single observation is left out
    - Re-weight posterior samples based on importance
  - **Pareto-smoothing**:
    - Stabilize importance weights, reducing the impact of extreme weights
    - E.g., if an observation left out has a large influence on the posterior
      distribution
    - Provide diagnostics to assess the reliability of importance weights

* Predictive Accuracy with Arviz
- If the inference data has the log-likelihood group
  ```
  pm.sample(idata_kwargs="log_likelihood": True)
  ```
  metrics such as WAIC and LOO (with / without ELPD) can be automatically
  computed

// TODO: Add pic

- In the first section
  - The first row is ELPD
  - The second row is the effective number of parameters
- In the second section, there is the Pareto k diagnostic
  - Since all the values are between 0 and 0.7, the approximation can be trusted

* Comparing Predictive Accuracy with Arviz
- In general the predictive accuracy metrics should be interpreted in relation
  to other models

// TODO: Add pic about `az.compare` and explanation

// ## 5.5, Model averaging

* Model Averaging
- You have multiple models explaining the data: what do you do?
  1. Select a single model
     - Simple solution used in frequentist approach
     - "Model selection"
  2. Report all the models with their informations (e.g., standard errors,
     posterior predictive checks)
     - Express advantages and shortcomings of the models
  3. Average all the models
     - Build a meta-model using a weighted average of each model
     - Weight prediction by the difference between information criteria (e.g.,
       WAIC, LOO) of the models
     - A hierarchical model is a continuous versions of multiple discrete models

//## 5.6, Bayes factors

* Evidence of Data Given a Model
- The Bayesian way to compare $k$ models is to calculate the evidence of each
  model $\Pr(Y | M_k)$, i.e., the probability of observed data $Y$ given each
  model $M_k$
  - Typically we ignore the evidence when we do parameter inference

- Consider the Bayes theorem for the parameters $\theta$ and the data $Y$, given
  a model $M_k$
  $$
  \Pr(\theta | Y, M_k)
  = \frac{\Pr(Y | \theta, M_k) \Pr(\theta | M_k)}{\Pr(Y | M_k)}
  $$
- We find the parameters $\theta$ that maximizes the ratio, independently of the
  probability of the evidence
  $$
  \argmax_{\theta} \Pr(\theta | y, M_k)
  = \argmax_{\theta} \Pr(y|\theta, M_k) \Pr(\theta | M_k)
  $$
- Even if we need to choose the best model among $M_1, ..., M_k$ we can pick the
  one that maximizes

  $$
  \argmax_k \Pr(M_k | y) \propto \Pr(y | M_k) \Pr(M_k)
  $$

* Bayes Factors
- The Bayes factors are defined as the ratio of the two marginal likelihoods
  under competing hypotheses

  $$
  BF = \frac{\Pr(y|M_0)}{\Pr(y|M_1)}
  $$
  where $BF > 1$ means that the model 0 explains the data better than model 1
  \begingroup \scriptsize
  | **Bayes factor**   | **Support**  |
  |----------|----------|
  | 1-3         | Anecdotal |
  | 3-10     | Moderate         |
  | 10-30 | Strong |
  | 30-100 | Very strong |
  | >100 | Extreme |
  \endgroup

- Intuition
  - Bayes factors are a quantitative tool that helps compare how likely two
    competing explanations (i.e., models) are, given the evidence you find
  - Bayes factors are like a scale that weigh how much evidence supports one
    theory over another

* Assumption of Bayes Factors
- The assumption of Bayes factor is that the models have the same prior
  probability
- Otherwise we need to compute the "posterior odds" as "Bayes factors" x "prior
  odds"

  $$
  \frac{\Pr(M_0 | y)}{\Pr(M_1 | y)}
  = \frac{\Pr(y | M_0)}{\Pr(y | M_1)} \frac{\Pr(M_0)}{\Pr(M_1)}
  = \text{Bayes factors} \times \text{prior odds}
  $$

* Bayes Factors: Pros and Cons
- Looking at the definition of marginal likelihood (aka evidence):

  $$
  p(y) = \int_{\theta} p(y|\theta) p(\theta) d\theta
  $$

- Making the dependency of the model $M_k$ explicit

  $$
  p(y | M_k) = \int_{\theta_k} p(y|\theta_k, M_k) p(\theta_k, M_k) d\theta_k
  $$

- Pros
  - Models with more parameters have a larger prior, so the Bayes factor has a
    built-in Occam's Razor
- Cons
  - The marginal likelihood needs to be computed numerically over a large
    dimensional space
  - The marginal likelihood depends on the value of the prior
    - Changing the prior might not affect the inference of $\theta$ but have a
      direct effect on the marginal likelihood

* Hierarchical Models: Candies in a Jar Examples
- Each classroom has a jar filled with candies, each different but coming from
  the same candy shop
- Kids in each classroom need to guess the number of candies in each jar

- Individual guesses
  - Think of each jar as its own little puzzle
  - E.g., guess based on how big the jar is, how filled it is
  - Each jar has certain "parameters"
- Group learning
  - Consider what you learn from other jars since they come from the same candy
    shop
  - E.g., the shop prefers to use a certain type of candies, or fills the jar up
    to a certain level
  - The jars have certain "hyper-parameters"
- Sharing info
  - As you make more guesses, you start sharing what you have learned with your
    friends about each jar
  - The hierarchical model lets the info flow across models for individual jar

* Computing Bayes Factors as Hierarchical Models
- The computation of Bayes factors can be framed as a hierarchical model
  - The high-level parameter is an index assigned to each model and sampled from
    a categorical distribution
- We perform inference of the competing models at the same time, using a
  discrete variable jumping between models
  - The proportion we use to sample each model is proportional to $\Pr(M_k | y)$
- Then we compute the Bayes factors

- The models can be different in the prior, in the likelihood, or both

* Common Problems When Computing Bayes Factors

1. If one model is better than the other, then we will spend more time sampling
   from it
   - Cons: under-sample one of the models
2. Values of the parameters are updated, even when the parameters are not used
   to fit that model
   - E.g., when model 0 is chosen, the parameters in model 1 are updated, but
     they are only restricted by the prior
   - If the prior is too vague, the parameter values might be too far from
     previous accepted values and the step is rejected
   - TODO: ?

- Solutions to improve sampling
  - Force both models to be visited equally
  - Use "pseudo priors"

* Using Sequential Monte Carlo to Compute Bayes Factors
- TODO

### ############################################################################
### Bayes Factors and Information Criteria
### ############################################################################

*
- If we take the log of Bayes factors, we turn ratio of marginal likelihood into
  a difference, which is similar to comparing differences in information criteria
- We can interpret each marginal likelihood as having:
  - a fitting term (i.e., how well the model fits the data)
  - penalizing term (i.g., averaging over the prior)
    - more parameters $\to$ more diffused the prior $\to$ greater penalty

*
- TODO

//## 5.8, Regularizing priors
## Regularizing priors

## #############################################################################
## Regularizing Priors
## #############################################################################

* Priors and Regularization
- Using weakly/informative priors is a way of pushing a model to prevent
  overfitting and generalize well
- This is similar to the idea of "regularization"

- Regularization
  - Reduce information that a model can represent and reduce chances to capture
    noise instead of signal
  - E.g., penalize large values for the parameters in a model
  - E.g., ridge and Lasso regression applies regularization to least square
    method

* Popular Regularization Methods in Bayesian Framework
- Ridge regression
  - Normal distribution for coefficients of linear model, pushing them toward
    zero
- Lasso regression
  - MAP of posterior using Laplace priors for coefficients
  - Because Laplace distribution looks like Gaussian with a sharp peak at zero,
    it provides "variable selection" since it induces sparsity of model

// # 7, Mixture models
// ## 7.1, Understanding mixture models

## #############################################################################
## Mixture Models
## #############################################################################

* Mixture Models
- Mixture models are models that assume that data comes from a mixture of
  distributions or where the solution can be approximated as a mix of simpler
  distributions

- Mixtures can model data from sub-populations
  - E.g., distribution of heights in adult human population, made of male and
    female
  - E.g., clustering of handwritten digits (e.g., 10 sub-populations)

- Mixture models as statistical trick to handle complex distributions
  - E.g., mix of Gaussians to describe an arbitrary distribution
    - E.g., multimodal, skewed distributions
    - The number of distributions depends on the accuracy of the approximation
      and the details of the data
  - E.g., Kernel density estimation (KDE) is a (non-Bayesian) non-parametric
    estimation technique
    - Place a Gaussian with a fixed variance on top of each data points
    - Use the sums of all the individual Gaussians to approximate the empirical
      distribution of the data

//## 7.2, Finite mixture models

* Finite Mixture Models
- = the PDF of the observed data is a weighted sum of the PDFs of $K$ subgroups

  $$
  p(y) = \sum_{i=1}^K w_i p(y | theta_i)
  $$

  where:
  - $K$ is finite
  - $w_i \in [0, 1]$ (it's like the probability of component $i$)
  - $\sum_i w_i = 1$
  - $p(y | \theta_i)$ are simpler distributions (e.g., Gaussian or Poisson)

* Conceptual Solution of a Mixture Model
- The assumption of a mixture model is that the data is generated by $K$
  underlying distributions / components
  - In other words, each data point is assumed to come from one of the
    components, but we don't know which

- The goal is to determine which component of the model $k$ the data point $x$
  most likely belongs to
  - For each point $x$, assign probabilities of belonging to one of the $K$
    components $\Pr(k | x)$
  - This is modeled as a random variable, which is called "latent variable"
    since it can't be observed
  - E.g., for two components ($K = 2$) we use a Bernoulli, using a Beta
    distribution as prior (since it is conjugate prior for Bernoulli)
  - E.g., for $K$ outcomes we can use as prior
    - A Categorial distribution to generalize the Bernoulli
    - A Dirichlet distribution to generalize the Beta distribution

- One can estimate the likelihood of the observed data based on:
  - Parameters of the individual components
  - Probabilities that a given data point belongs to each component

* Categorical Distribution
- Discrete distribution representing "rolling a $K$-sided unfair die" or
  "choosing a random card from a deck of cards"
  - It generalizes a Bernoulli distribution $K = 2$
- It is parametrized with probabilities for each possible outcome
  $(p_1, p_2, ..., p_K)$, where $p_i$ is the probability of outcome $i$

* Dirichlet Distribution
- Defined in a simplex which is a generalization of a triangle in
  $K$-dimensions, where $K$ vectors elements are in $[0, 1]$ and sum to $1$
  - A 1d simplex is an interval
  - A 2d simplex is a triangle
  - A 3d simplex is a tetrahedron
  - ...

- Dirichlet distribution generalizes the Beta distribution
  - Beta models the probability of a single proportion (e.g., the probability of
    success in a Bernoulli trial)
  - Beta models 2 outcomes, one with probability $p$ and the other with $1-p$
  - It uses two parameters to describe its shape

- The Dirichlet distribution models the probability of $K$ outcomes
  - It represents the uncertainty over the proportions of different outcomes in
    a multinomial experiment

// TODO: Show distribution

* Dirichlet Distribution: Examples
- Bucket of colored balls
  - You have a bucket of colored balls, each ball comes in 3 colors
  - You want to figure out the probability of picking a ball of each color
  - You are uncertain about the probability and you model that uncertainty

- You want to divide a pie into 4 different slices
  - You want to model the size of the slices (making sure they split the entire
    pie), modeling the uncertainty

* Re-Parametrization Using Marginalization
- Consider a mixture model that include latent variables representing the
  component from which each observation is drawn
- Performing posterior sampling on these models is inefficient for several
  reasons:
  - Discrete variables introduce discontinuities
  - Latent variable introduces dependencies

- A solution is "marginalization"
  - Removing the latent variable by integrating out from the model
  - The observations are directly modeled from a mixture distribution
  - This makes sampling more efficient
  - The problem is that the model becomes more complex mathematically
  - `pymc` has distributions (e.g., `NormalMixture`) where the latent variable
    is already marginalized

// ## 7.3, The non-identifiability of mixture models

* Non-Identifiability of Parameters
- Parameters in a model are "not identifiable" when one or more parameters
  cannot be uniquely determined

- In practice multiple model fits give different parameters corresponding to the
  same model
  - E.g., given a bimodal distribution sum of two Gaussians, solving the same
    model can switch the value of the means (aka "label switching problem")
  - E.g., variables with high-correlation in linear models

- Solutions
  - Arrange the means of the components to be in increasing order
    - E.g., in `pymc` add a "potential" to the likelihood (which doesn't depend
      on the data) so that a constraint is not violated
  - Use informative priors to guide a model towards a canonical representation

// ### How to choose K

* How to Choose K
- How to decide the number of components $K$ in a finite mixture model?

- Solution
  - Start with a small number of components $K$
  - Increase $K$ to improve the model-fit evaluation
  - Use model selection techniques to find best trade-off
    - E.g., using posterior-predictive checks, WAIC, LOO, or domain expertise

// TODO: Add plots

## #############################################################################
## 7.5, Zero-Inflated and Hurdle Models
## #############################################################################

*
- When counting things, it is possible to get a count of zero

- Problem: some models (e.g., Poisson, Negative Binomial distribution) can
  generate fewer zeros compared to the data

- Solutions
1. We can improve the model (e.g., use a better model, non-parametric one)
2. We can assume we have a mixture model, with one model for the zero element and
   one model giving non-zero elements, aka "Zero-inflated distributions"
   - Family of distributions allowing for "extra" zeros, e.g.,
     - zero-inflated Poisson
     - zero-inflated Negative Binomial
     - zero-inflated Binomial

* Hurdle Models
- A Bernoulli model determines if the count variable is zero or a different
  distribution truncated at 0, i.e., which doesn't assume the value 0

- E.g., hurdle Poisson, NegativeBinomial, Gamma, LogNormal

* Zero-Inflated vs Hurdle Models
- Zero-inflated models are a mixture of zeros and a distribution of zeros and
  non-zeros
  - The probability $\Pr(x = 0)$ can only be larger than the base distribution,
    i.e., the probability of zero is "inflated"
- Hurdle models are a mixture of zeros and non-zeros
  - The probability $\Pr(x = 0)$ is independent of the base distribution

* Hanging root-ograms
- Useful for treating issues such as over-dispersion and/or excess zeros in count
  data models
1) Plot the square root of observed and predicted values
   - It makes it simper to adjust for scale differences
2) Bars of observed data are hanging from the expected values
   - It makes it simple to see if it's a good fit or not by comparing the bottom
     of the values to a base

## #############################################################################
## 7.6, Mixture Models and Clustering
## #############################################################################

* Clustering
- Goal: group objects so that the objects in a given group (aka cluster) are
  "closer" to each other than to those in the other groups
  - Degree of closeness is computed using a distance (e.g., Euclidean distance)

- Clustering is an unsupervised learning task
  - Similar to classification but without knowing the correct labels

* Soft- vs Hard- Clustering
- Soft-clustering computes the probability of each data point belonging to each
  cluster
- Hard-clustering assigns each point to a single cluster

- One can turn soft-clustering into hard- by assigning each data point to the
  cluster with the highest probability
  - E.g., assigning points to the cluster with highest probability
  - E.g., using a threshold for probability of 0.5 (as in classification for
    logistic regression)

* Probabilistic Clustering
- Aka "model-based clustering"
- = clustering using probabilistic model, i.e., compute the probability of each
  point belonging to one of the customers
- E.g., we assume that data is generated by a mixture models

## #############################################################################
## 7.7, Non-Finite Mixture Models
## #############################################################################

* How Many Mixture Models to Use?
- For some problems, it is easy to choose the number of mixtures to use, since
  we know how many groups there are in the data
  - E.g., when clustering handwritten digits we know there are 10 groups

- For other problems, we can't choose the number of groups a priori and we want
  it to estimate from the data
  - E.g., Dirichlet process

* Parametric vs Non-Parametric Models
- Parametric models have a fixed number of parameters
- Non-parametric models have (theoretically) an infinite number of parameters
  - Very flexible
  - The data decides how many parameters are needed
  - E.g., Gaussian process (GP), Bayesian Additive Regression Trees (BART),
    Dirichlet process (DP)

* Dirichlet Process
- Dirichlet distribution is the $n$-dimensional generalization of beta
  distribution
- Dirichlet process (DP) is the infinite-dimensional generalization of the
  Dirichlet distribution
  - A draw from a DP is actually a (discrete) Dirichlet distribution

- A DP has:
  - A base distribution $\mathcal{H}$ (e.g., Gaussian, Poisson, Laplace)
  - $\alpha$ a concentration parameter
    - Increasing $\alpha$ means less and less concentrated realization
    - For $\alpha \to \infty$ the realization of a DP are equal to the base
      distribution

* Categorical Distribution
- The categorical distribution (the most general discrete distribution) is
  parameterized specifying the probabilities of each possible outcome
- It is specified by:
  - Indicating the positions on the x axis and the height on the y axis
  - $x$ positions are integers
  - $y$ heights must sum to 1

- A generalization of this is to have $x$ sampled from $\mathcal{H}$
  - $\mathcal{H}$ to be a Gaussian, so $x$ are on the real line
  - $\mathcal{H}$ to be a Beta, so $x$ are in [0, 1]
  - $\mathcal{H}$ to be a Poisson, so $x$ are non-negative integers 0, 1, 2, ...

* Stick-Breaking Process
- = process to generate values on the y axis so that the sum is 1
- You start with a stick of length 1
- Break it into two parts (not necessarily equal)
  - Use the "concentration parameter" $\alpha$ to control the size of the break
- Save the first part
- Pick the second part and break it again
- Repeat until you get $K$ values

* Dirichlet Process Using Stick-Breaking
- The locations are sampled from the base distribution
- The weights are controlled by $\alpha$
- As $\alpha \to \infty$ the DP distribution approximates the base distribution

* Infinite Mixture Model
- We can place a Gaussian on each data point and weight from a Dirichlet process
- The same approach can be use for Laplace distribution

## #############################################################################
## 7.8, Continuous Mixtures
## #############################################################################

// 8, Gaussian processes
// 9, Bayesian additive regression

# ##############################################################################
# Inference Engines
# ##############################################################################

// 10, Inference engines
// AIMA 13.4

## #############################################################################
## 10.1, Inference Engines
## #############################################################################

* Inference Engines as Black
- Bayesian methods are numerically challenging
  - Intractable / computationally intractable integral to solve

- Probabilistic programming separates:
  1. Model building
  - Users should not care how sampling is carried out
  2. Inference process (can be a black box, leave PyMC to handle computation)

- Understanding how the posterior is sampled can help understand how different
  methods can fail
  - E.g., diagnose samples
