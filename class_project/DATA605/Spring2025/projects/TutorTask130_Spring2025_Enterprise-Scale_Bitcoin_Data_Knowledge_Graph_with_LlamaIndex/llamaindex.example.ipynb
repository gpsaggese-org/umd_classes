{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f78f7e-2dee-45d6-9d37-7a55eeaae283",
   "metadata": {},
   "source": [
    "# Enterprise-Scale Bitcoin Data Knowledge Graph with LlamaIndex\n",
    "\n",
    "This notebook demonstrates the following\n",
    "1. Ingest Raw Bitcoin Blocks, Economic Indicators and On-Chain Metrics\n",
    "2. Building a Knowledge Graph in LlamaIndex with a Neo4J Graph Store\n",
    "3. Intelligent querying using LlamaIndex Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3a9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226667e-cab5-479c-be6a-6b7d6f580a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from llamaindex_utils import (\n",
    "    ingest_raw_block_data, \n",
    "    ingest_onchain_metrics, \n",
    "    ingest_economic_indicators,\n",
    "    get_raw_block_data,\n",
    "    get_onchain_metrics,\n",
    "    get_economic_indicators)\n",
    "from datetime import timedelta, datetime\n",
    "from utils.triplets import TripletGenerator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llamaindex_utils import get_neo4j_graph_store\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llamaindex_utils import LlamaAgents\n",
    "import nest_asyncio\n",
    "\n",
    "# to run async code in notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configure logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f64c3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To begin, we set some LlamaIndex specific settings\n",
    "1. LLM - OpenAI gpt-4.1-mini\n",
    "2. Embedding Model - all-MiniLM-L6-v2\n",
    "\n",
    "You may swap out different models as per need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c7680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"devops/env/default.env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "llm = OpenAI(model=\"gpt-4.1-mini\", \n",
    "             temperature=0,\n",
    "             api_key=OPENAI_API_KEY)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f084a",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "We start by ingesting the following data:\n",
    "1. Raw Bitcoin Blocks from [Public Node](https://bitcoin-rpc.publicnode.com)\n",
    "2. Economic Indicators like S&P500, CPI, Federal Funds Rate, etc from [FRED](https://fred.stlouisfed.org/docs/api/fred/)\n",
    "3. On-Chain Metrics like Transaction Volume, Hash Rate, etc from [Blockchain.info](https://api.blockchain.info/charts)\n",
    "\n",
    "**Ingesting such high quantities of data while respecting rate limit takes a while!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = timedelta(days=10) # We define the period of ingestion from current time\n",
    "\n",
    "ingest_raw_block_data(td)\n",
    "ingest_economic_indicators(td)\n",
    "ingest_onchain_metrics(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385266c",
   "metadata": {},
   "source": [
    "## Triplets Generation\n",
    "Triplets are a sequence of three entities that codifies a statement about data in the form of subject–predicate–object expressions. <br>\n",
    "For e.g If Mary is an Engineer and John and Mary are friends then triplets for this would be: <br>\n",
    "Mary -> IS -> Engineer <br>\n",
    "Mary -> FRIENDS -> John <br>\n",
    "\n",
    "For our use case Triplets are of the form:\n",
    "Block: 8914 -> FOLLOWS -> Block: 8913<br>\n",
    "Block: 1234 -> CONTAINS -> Transaction: s4d56f7g8hu9j <br>\n",
    "Sp500 -> HAS_VALUE_ON -> 2025-03-26<br>\n",
    "and so on\n",
    "\n",
    "These triplets are generated by breaking down the structured data that we ingested, through code. Alternatively LLMs can also be used to generate triplets, but since we are not dealing with semantic data, we are using hard-code generated triplets to save a LOT of LLM API calls\n",
    "\n",
    "Triplets are made up of entities (Blocks, Transactions, CPI, etc) that are joined by relationships (HAS_VALUE, CONTAINS, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_data = get_raw_block_data()\n",
    "economic_data = get_onchain_metrics()\n",
    "onchain_data = get_economic_indicators()\n",
    "\n",
    "triplet_generator = TripletGenerator()\n",
    "nodes, relations, text_nodes = triplet_generator.load_and_process_data(blocks_data, economic_data, onchain_data)\n",
    "logger.info(f\"Generated {len(nodes)} nodes\")\n",
    "logger.info(f\"Generated {len(relations)} relations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b34f9",
   "metadata": {},
   "source": [
    "### Batch Embeddings\n",
    "We have now generated the core components for creating a Knowledge Graph using triplets <br>\n",
    "We can also embed these components to enable vector based similarity search. To speed things up, we will use batching.\n",
    "\n",
    "Since the embedding model runs on you local system, generation times will vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on BaseNode embedding texts\n",
    "node_texts = []\n",
    "for node in nodes:\n",
    "    node_texts.append(\"\\n\".join([f\"{key}: {node.properties[key]}\" for key in node.properties.keys()]))\n",
    "    \n",
    "\n",
    "node_embeddings = embed_model.get_text_embedding_batch(node_texts)\n",
    "text_embeddings = embed_model.get_text_embedding_batch([text_node.text for text_node in text_nodes])\n",
    "for node, embedding in zip(nodes, node_embeddings):\n",
    "    node.embedding = embedding\n",
    "for text_node, embedding in zip(text_nodes, text_embeddings):\n",
    "    text_node.embedding = embedding\n",
    "\n",
    "logger.info(f\"Embedded {len(nodes)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1dc5c",
   "metadata": {},
   "source": [
    "## Building the Knowledge Graph\n",
    "We are finally ready to build a LlamaIndex Knowledge Graph. This involves two components:\n",
    "1. **Graph Store** <br>\n",
    "The Graph Store is the underlying DB for the Knowledge Graph. LlamaIndex supports a variety of Graph Stores including an in-memory one. Here we will use Neo4j Graph Store. This offloads storage persistence responsibility as well as allows us to perform similarity search based on the embeddings we generated previously\n",
    "2. **Graph Index** <br>\n",
    "The Graph Index is the data structure that allows us to quickly retrieve relevant context for a user query. LlamaIndex offers KnowledgeGraphIndex(deprecated) and PropertyGraphIndex. This Index enables us to perform complex queries and leverage AI Agents to interact with our data, providing a high-level interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ecb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - PropertyGraphIndex created with schema: \n",
      "{'node_props': {'Block': [{'property': 'hash', 'type': 'TEXT', 'values': ['00000000000000000000ab2d5af936a7c0b91f4216ac3a3e7f0b'], 'distinct_count': 1}, {'property': 'height', 'type': 'INTEGER', 'min': '894214', 'max': '894214', 'distinct_count': 1}, {'property': 'timestamp', 'type': 'INTEGER', 'min': '1745784304', 'max': '1745784304', 'distinct_count': 1}, {'property': 'name', 'type': 'STRING', 'values': ['894214'], 'distinct_count': 1}, {'property': 'month', 'type': 'INTEGER', 'min': '4', 'max': '4', 'distinct_count': 1}, {'property': 'hour', 'type': 'INTEGER', 'min': '20', 'max': '20', 'distinct_count': 1}, {'property': 'size', 'type': 'INTEGER', 'min': '1034417', 'max': '1034417', 'distinct_count': 1}, {'property': 'day', 'type': 'INTEGER', 'min': '27', 'max': '27', 'distinct_count': 1}, {'property': 'difficulty', 'type': 'FLOAT', 'min': '1.232343879770509E14', 'max': '1.232343879770509E14', 'distinct_count': 1}, {'property': 'datetime', 'type': 'STRING', 'values': ['2025-04-27 20:...\n"
     ]
    }
   ],
   "source": [
    "# You may pass your username/password/url here\n",
    "graph_store = get_neo4j_graph_store()\n",
    "\n",
    "# Add Nodes, Relations and TextNodes to the Graph Store\n",
    "graph_store.upsert_nodes(nodes)\n",
    "graph_store.upsert_relations(relations)\n",
    "graph_store.upsert_llama_nodes(text_nodes)\n",
    "\n",
    "# Initialize Graph Index with the Graph Store\n",
    "kg_index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "logger.info(f\"PropertyGraphIndex created with schema: \\n{str(kg_index.property_graph_store.structured_schema)[:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0354281",
   "metadata": {},
   "source": [
    "## Querying the Knowledge Graph\n",
    "We can directly query the Knowledge Graph by creating a Query Engine. Internally it calls an LLM and our Graph Store to parse raw data for natural language queries and return human-readable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab88838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The block with height 894214 contains multiple transactions, including those with the following identifiers: 675a45c28fb1b1e5b458328478a711eccbec20f8a155a7ec7eada7dcb65b6f80, ed9590df5777b94de6b271ba4d1dfa28c7a1c5c518164a32b25b9ead03704251, 081a66b7cd3e13ddb9a97faaa3ddf2f170daf44fb4466b3434ece9d4866d0d80, 956abb004f3114c32b8edd4d78f8acdb8fa01de5e3ffb3b516041481e7df7164, and 33ee38bbcd2e498287de880a94e8cfbb31a9fec22574afaccc6766f0e3b136c3. Several of these transactions send funds to the address bc1pq3qht4k45ccx89paqpd3axfwf4cmpyyxgwp79n6lxl8qv3hx8wuslyufll, while one transaction sends to addresses bc1pnx3x47zagukpjychkzk3tmzclfyu3rcd72f9nllz0cukve3xj7tqwj2ra5 and bc1pf39ct659za9j6azccfh3jpptk9s6us8lnjll9y9wuemq443ah6qqtu45dz.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = kg_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    embedding_mode=\"hybrid\",\n",
    "    response_mode=\"tree_summarize\", #tree_summarize, no_text\n",
    "    include_text=True,\n",
    ")\n",
    "# Modify this query as per need\n",
    "query_engine.query(\"Tell me about the Block with height 894214\").response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e7505",
   "metadata": {},
   "source": [
    "## LlamaIndex Agents for Knowledge Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af1130",
   "metadata": {},
   "source": [
    "\n",
    "LlamaIndex has many default retrievers that can be directly used to perform variety of queries on our Knowledge Graph. <br>\n",
    "For more complex and highly-specific queries we will leverage LlamaIndex Agents.<br>\n",
    "- A lot of Agents we use here are highly similar to **CypherTemplateRetriever** where the LLM fills in a Cypher query to retrieve the relevant results from the Knowledge Graph.\n",
    "- Obviously we can't have Cypher query templates for all possible cases, hence we also have Agents that use\n",
    "    - **VectorContextRetriever** to perform vector similarity search\n",
    "    - **TextToCypherRetriever** where the LLM will create a Cypher query from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d99e2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_agents = LlamaAgents(kg_index=kg_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf19f2a",
   "metadata": {},
   "source": [
    "#### Example: Find specific block details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e9ada5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Block with height 894214 was created on April 27, 2025, at 20:05:04 (UTC). \\n\\nIf you need more details about this block or its transactions, feel free to ask!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llama_agents.query(\"When was block with 894214 created?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806cf023",
   "metadata": {},
   "source": [
    "#### Example: Trace Funds sent to an Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc2b448f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Bitcoin address bc1pq3qht4k45ccx89paqpd3axfwf4cmpyyxgwp79n6lxl8qv3hx8wuslyufll has received multiple small-value transactions. Here is a summary of the received funds:\\n\\n- The transactions are all recorded at block height 894214.\\n- The timestamps for these transactions are around 2025-04-27 20:05:04.\\n- The received values range from very small amounts like 0.0000033 BTC to about 0.0000488 BTC.\\n- There are many individual transactions, each sending a small fraction of a Bitcoin to this address.\\n\\nNo sent transactions were found in the latest 20 transactions for this address, indicating these are incoming funds.\\n\\nIf you want, I can trace where these received funds were sent afterward or provide details on specific transactions. Let me know how you would like to proceed.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llama_agents.query(\"Trace the funds sent to this btc address bc1pq3qht4k45ccx89paqpd3axfwf4cmpyyxgwp79n6lxl8qv3hx8wuslyufll\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
