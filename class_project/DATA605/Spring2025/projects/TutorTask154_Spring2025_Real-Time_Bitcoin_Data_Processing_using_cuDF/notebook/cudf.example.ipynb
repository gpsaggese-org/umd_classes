{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b10c01",
   "metadata": {},
   "source": [
    "# Real-Time Bitcoin Data Processing using cuDF\n",
    "\n",
    "This notebook demonstrates end-to-end Bitcoin data processing using NVIDIA RAPIDS cuDF for GPU-accelerated analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Fetch historical Bitcoin price data\n",
    "2. Process the data using GPU-accelerated operations\n",
    "3. Calculate technical indicators for Bitcoin analysis\n",
    "4. Visualize price trends and indicators\n",
    "5. Demonstrate real-time data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b6b6d",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560110ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports.\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Third-party library imports.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the parent directory to sys.path.\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import utility functions from our project.\n",
    "from utils.cudf_utils import (\n",
    "    fetch_bitcoin_price, fetch_historical_data, add_to_dataframe,\n",
    "    compute_moving_averages, compute_volatility, compute_rate_of_change,\n",
    "    compute_rsi, plot_bitcoin_data, save_to_csv, load_from_csv\n",
    ")\n",
    "\n",
    "# Import cuDF for GPU-accelerated data processing.\n",
    "import cudf\n",
    "\n",
    "# Load environment variables (for API keys).\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa794ba",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "\n",
    "First, let's verify that we have a CUDA-capable GPU available for acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cuda():\n",
    "    \"\"\"Check if CUDA is available and print GPU information\"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        print(\"[SUCCESS] CUDA is available! Using GPU acceleration with cuDF.\")\n",
    "        \n",
    "        # Get GPU information.\n",
    "        gpu_info = cp.cuda.runtime.getDeviceProperties(0)\n",
    "        print(f\"[INFO] GPU Device: {gpu_info['name'].decode()}\")\n",
    "        print(f\"[INFO] CUDA Compute Capability: {gpu_info['major']}.{gpu_info['minor']}\")\n",
    "        print(f\"[INFO] Total Memory: {gpu_info['totalGlobalMem'] / (1024**3):.2f} GB\")\n",
    "        \n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"[WARNING] CuPy not found. Make sure CUDA is properly configured for GPU acceleration.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error initializing CUDA: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check CUDA availability.\n",
    "has_cuda = check_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e5cad",
   "metadata": {},
   "source": [
    "## Historical Data Analysis\n",
    "\n",
    "Let's start by fetching and analyzing historical Bitcoin price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of days of historical data to analyze.\n",
    "days = 90\n",
    "print(f\"[FETCHING] Fetching {days} days of historical Bitcoin price data...\")\n",
    "\n",
    "# Start timing.\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch historical data.\n",
    "historical_data = fetch_historical_data(days=days)\n",
    "\n",
    "if historical_data is None or len(historical_data) == 0:\n",
    "    print(\"[ERROR] Failed to fetch historical data. Please check your internet connection.\")\n",
    "else:\n",
    "    fetch_time = time.time() - start_time\n",
    "    print(f\"[SUCCESS] Successfully fetched {len(historical_data)} historical data points in {fetch_time:.2f} seconds.\")\n",
    "    print(f\"[DATE RANGE] Date range: {historical_data['timestamp'].min()} to {historical_data['timestamp'].max()}\")\n",
    "    print(f\"[PRICE RANGE] Price range: ${historical_data['price'].min():.2f} to ${historical_data['price'].max():.2f}\")\n",
    "    \n",
    "    # Display the first few rows.\n",
    "    historical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f34cc",
   "metadata": {},
   "source": [
    "## Technical Indicator Calculation\n",
    "\n",
    "Now, let's calculate various technical indicators using cuDF's GPU-accelerated functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process historical data.\n",
    "print(\"[PROCESSING] Computing technical indicators...\")\n",
    "start_time = time.time()\n",
    "\n",
    "if 'historical_data' in locals() and historical_data is not None and len(historical_data) > 0:\n",
    "    # Compute moving averages.\n",
    "    historical_data = compute_moving_averages(historical_data, windows=[7, 20, 50])\n",
    "    \n",
    "    # Compute volatility.\n",
    "    historical_data = compute_volatility(historical_data, window=20)\n",
    "    \n",
    "    # Compute rate of change.\n",
    "    historical_data = compute_rate_of_change(historical_data, periods=[1, 7, 30])\n",
    "    \n",
    "    # Compute RSI.\n",
    "    historical_data = compute_rsi(historical_data, window=14)\n",
    "    \n",
    "    process_time = time.time() - start_time\n",
    "    print(f\"[SUCCESS] Finished computing indicators in {process_time:.2f} seconds.\")\n",
    "    \n",
    "    # Display the data with indicators.\n",
    "    historical_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978dce60",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Let's visualize the Bitcoin price data along with technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094289d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive visualization.\n",
    "if 'historical_data' in locals() and historical_data is not None and len(historical_data) > 0:\n",
    "    print(\"[VISUALIZATION] Generating visualization of historical data...\")\n",
    "    \n",
    "    # Plot Bitcoin data with technical indicators.\n",
    "    fig = plot_bitcoin_data(historical_data, \n",
    "                           title=f\"{days}-Day Bitcoin Price Analysis with cuDF\")\n",
    "    \n",
    "    # Display the plot.\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8886c12",
   "metadata": {},
   "source": [
    "## Real-Time Data Processing\n",
    "\n",
    "Now, let's demonstrate real-time data collection and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2386c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for real-time data collection.\n",
    "interval_seconds = 3  # seconds between data points.\n",
    "num_points = 10       # number of data points to collect.\n",
    "\n",
    "print(f\"[COLLECTING] Collecting {num_points} real-time Bitcoin price data points with {interval_seconds} second intervals...\")\n",
    "print(f\"[TIME] This will take approximately {num_points * interval_seconds} seconds. Please wait...\")\n",
    "\n",
    "# Collect real-time data.\n",
    "realtime_data = None\n",
    "if has_cuda:  # Only proceed if CUDA is available.\n",
    "    from utils.cudf_utils import simulate_realtime\n",
    "    realtime_data = simulate_realtime(interval_seconds=interval_seconds, num_points=num_points)\n",
    "    \n",
    "    if realtime_data is not None and len(realtime_data) > 0:\n",
    "        print(f\"[SUCCESS] Successfully collected {len(realtime_data)} real-time data points.\")\n",
    "        \n",
    "        # Display the real-time data.\n",
    "        realtime_data.head(num_points)\n",
    "    else:\n",
    "        print(\"[ERROR] Failed to collect real-time data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731e3ea",
   "metadata": {},
   "source": [
    "## Processing Real-Time Data\n",
    "\n",
    "Let's process the real-time data and calculate technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process real-time data.\n",
    "if 'realtime_data' in locals() and realtime_data is not None and len(realtime_data) > 0:\n",
    "    print(\"[PROCESSING] Computing technical indicators for real-time data...\")\n",
    "    \n",
    "    # Adjust window sizes based on the amount of data available.\n",
    "    window_sizes = [min(3, len(realtime_data)-1), min(5, len(realtime_data)-1)]\n",
    "    window_sizes = [w for w in window_sizes if w > 0]\n",
    "    \n",
    "    if window_sizes:\n",
    "        # Compute technical indicators with appropriate window sizes.\n",
    "        realtime_data = compute_moving_averages(realtime_data, windows=window_sizes)\n",
    "        realtime_data = compute_volatility(realtime_data, window=window_sizes[0])\n",
    "        realtime_data = compute_rate_of_change(realtime_data, periods=[1])\n",
    "        \n",
    "        print(\"[SUCCESS] Finished computing indicators for real-time data.\")\n",
    "        \n",
    "        # Display the processed real-time data.\n",
    "        realtime_data.head(num_points)\n",
    "    else:\n",
    "        print(\"[WARNING] Not enough data points for technical indicators.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0123c",
   "metadata": {},
   "source": [
    "## Combining Historical and Real-Time Data\n",
    "\n",
    "Now, let's combine historical and real-time data for a comprehensive view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine historical and real-time data.\n",
    "if ('historical_data' in locals() and historical_data is not None and len(historical_data) > 0 and\n",
    "    'realtime_data' in locals() and realtime_data is not None and len(realtime_data) > 0):\n",
    "    \n",
    "    # Convert both DataFrames to pandas for easier concatenation.\n",
    "    hist_pdf = historical_data.to_pandas()\n",
    "    real_pdf = realtime_data.to_pandas()\n",
    "    \n",
    "    # Concatenate the DataFrames.\n",
    "    combined_pdf = pd.concat([hist_pdf, real_pdf], ignore_index=True)\n",
    "    \n",
    "    # Convert back to cuDF.\n",
    "    combined_data = cudf.DataFrame.from_pandas(combined_pdf)\n",
    "    \n",
    "    print(f\"[SUCCESS] Combined data has {len(combined_data)} rows\")\n",
    "    \n",
    "    # Recalculate technical indicators.\n",
    "    combined_data = compute_moving_averages(combined_data, windows=[7, 20, 50])\n",
    "    combined_data = compute_volatility(combined_data, window=20)\n",
    "    combined_data = compute_rate_of_change(combined_data, periods=[1, 7])\n",
    "    combined_data = compute_rsi(combined_data, window=14)\n",
    "    \n",
    "    # Display the combined data.\n",
    "    combined_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594e0bc",
   "metadata": {},
   "source": [
    "## Visualizing Combined Data\n",
    "\n",
    "Let's create a comprehensive visualization of the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize combined data.\n",
    "if 'combined_data' in locals() and combined_data is not None and len(combined_data) > 0:\n",
    "    print(\"[VISUALIZATION] Generating visualization of combined data...\")\n",
    "    \n",
    "    # Create plot with combined data.\n",
    "    fig_combined = plot_bitcoin_data(combined_data, \n",
    "                                    title=\"Bitcoin Price Analysis - Historical + Real-time Data\")\n",
    "    \n",
    "    # Display the plot.\n",
    "    fig_combined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbf6d2",
   "metadata": {},
   "source": [
    "## Saving the Data\n",
    "\n",
    "Let's save the processed data to a CSV file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data to CSV.\n",
    "if 'combined_data' in locals() and combined_data is not None and len(combined_data) > 0:\n",
    "    filename = \"bitcoin_data_combined.csv\"\n",
    "    save_to_csv(combined_data, filename=filename)\n",
    "    print(f\"[SUCCESS] Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb568d",
   "metadata": {},
   "source": [
    "## Bitcoin Price Forecasting\n",
    "\n",
    "Finally, let's implement a simple forecasting model to predict future Bitcoin prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import forecasting libraries.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def forecast_bitcoin_prices(historical_data, forecast_days=30):\n",
    "    \"\"\"Forecast Bitcoin prices using historical data\n",
    "    \n",
    "    Args:\n",
    "        historical_data (cudf.DataFrame): Historical Bitcoin price data\n",
    "        forecast_days (int): Number of days to forecast\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (historical_data_pandas, forecast_data_pandas) as pandas DataFrames\n",
    "    \"\"\"\n",
    "    print(f\"[FORECASTING] Forecasting Bitcoin prices for the next {forecast_days} days...\")\n",
    "    \n",
    "    if historical_data is None or len(historical_data) < 30:\n",
    "        print(\"[ERROR] Insufficient historical data for forecasting. Need at least 30 data points.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to pandas for forecasting.\n",
    "    df = historical_data.to_pandas()\n",
    "    \n",
    "    # Sort by timestamp.\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Set timestamp as index.\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Keep only the price column for basic forecasting.\n",
    "    price_series = df['price']\n",
    "    \n",
    "    # Create features for regression (using lag features).\n",
    "    X = np.column_stack([\n",
    "        price_series.shift(1).values[30:],\n",
    "        price_series.shift(7).values[30:],\n",
    "        price_series.shift(14).values[30:],\n",
    "        price_series.shift(30).values[30:],\n",
    "        price_series.rolling(7).mean().shift(1).values[30:],\n",
    "        price_series.rolling(14).mean().shift(1).values[30:],\n",
    "        price_series.rolling(30).mean().shift(1).values[30:],\n",
    "        price_series.rolling(7).std().shift(1).values[30:],\n",
    "        price_series.pct_change(periods=1).shift(1).values[30:],\n",
    "        price_series.pct_change(periods=7).shift(1).values[30:],\n",
    "    ])\n",
    "    \n",
    "    # Target variable.\n",
    "    y = price_series.values[30:]\n",
    "    \n",
    "    # Remove NaN rows.\n",
    "    valid_indices = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
    "    X_clean = X[valid_indices]\n",
    "    y_clean = y[valid_indices]\n",
    "    \n",
    "    # Standardize features.\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_clean)\n",
    "    \n",
    "    # Train a linear regression model.\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_scaled, y_clean)\n",
    "    \n",
    "    print(\"[SUCCESS] Model trained. Generating forecast...\")\n",
    "    \n",
    "    # Prepare data for forecasting.\n",
    "    forecast_horizon = forecast_days\n",
    "    forecast_dates = [df.index[-1] + timedelta(days=i+1) for i in range(forecast_horizon)]\n",
    "    \n",
    "    # Initialize with known values.\n",
    "    forecast_values = []\n",
    "    forecast_df = price_series.copy()\n",
    "    \n",
    "    # Step-by-step forecast.\n",
    "    for i in range(forecast_horizon):\n",
    "        # Get the latest data point.\n",
    "        latest_price = forecast_df.iloc[-1] if i == 0 else forecast_values[-1]\n",
    "        latest_price_lag1 = forecast_df.iloc[-1]\n",
    "        latest_price_lag7 = forecast_df.iloc[-7] if len(forecast_df) > 7 else forecast_df.iloc[0]\n",
    "        latest_price_lag14 = forecast_df.iloc[-14] if len(forecast_df) > 14 else forecast_df.iloc[0]\n",
    "        latest_price_lag30 = forecast_df.iloc[-30] if len(forecast_df) > 30 else forecast_df.iloc[0]\n",
    "        \n",
    "        # Calculate rolling stats.\n",
    "        if i == 0:\n",
    "            ma7 = forecast_df.rolling(7).mean().iloc[-1]\n",
    "            ma14 = forecast_df.rolling(14).mean().iloc[-1]\n",
    "            ma30 = forecast_df.rolling(30).mean().iloc[-1]\n",
    "            std7 = forecast_df.rolling(7).std().iloc[-1]\n",
    "            pct1 = forecast_df.pct_change(periods=1).iloc[-1]\n",
    "            pct7 = forecast_df.pct_change(periods=7).iloc[-1]\n",
    "        else:\n",
    "            # Append the latest prediction to the series.\n",
    "            temp_series = pd.concat([forecast_df, pd.Series([forecast_values[-1]], index=[forecast_dates[i-1]])])\n",
    "            ma7 = temp_series.rolling(7).mean().iloc[-1]\n",
    "            ma14 = temp_series.rolling(14).mean().iloc[-1]\n",
    "            ma30 = temp_series.rolling(30).mean().iloc[-1]\n",
    "            std7 = temp_series.rolling(7).std().iloc[-1]\n",
    "            pct1 = (temp_series.iloc[-1] / temp_series.iloc[-2]) - 1 if len(temp_series) > 1 else 0\n",
    "            pct7 = (temp_series.iloc[-1] / temp_series.iloc[-7]) - 1 if len(temp_series) > 7 else 0\n",
    "        \n",
    "        # Create feature vector.\n",
    "        X_forecast = np.array([[\n",
    "            latest_price_lag1,\n",
    "            latest_price_lag7,\n",
    "            latest_price_lag14,\n",
    "            latest_price_lag30,\n",
    "            ma7,\n",
    "            ma14,\n",
    "            ma30,\n",
    "            std7,\n",
    "            pct1,\n",
    "            pct7\n",
    "        ]])\n",
    "        \n",
    "        # Scale the features.\n",
    "        X_forecast_scaled = scaler.transform(X_forecast)\n",
    "        \n",
    "        # Make prediction.\n",
    "        forecast_price = model.predict(X_forecast_scaled)[0]\n",
    "        forecast_values.append(forecast_price)\n",
    "    \n",
    "    # Create DataFrame with forecasted values.\n",
    "    forecast_result = pd.DataFrame({'price': forecast_values}, index=forecast_dates)\n",
    "    \n",
    "    # Add confidence intervals (simple approach using historical volatility).\n",
    "    volatility = df['price'].pct_change().std() * np.sqrt(forecast_horizon)\n",
    "    forecast_result['lower_bound'] = forecast_result['price'] * (1 - volatility * 1.96)\n",
    "    forecast_result['upper_bound'] = forecast_result['price'] * (1 + volatility * 1.96)\n",
    "    \n",
    "    print(f\"[SUCCESS] 30-day forecast generated with confidence intervals.\")\n",
    "    \n",
    "    return df, forecast_result\n",
    "\n",
    "# Run forecasting if we have historical data.\n",
    "if 'historical_data' in locals() and historical_data is not None and len(historical_data) > 0:\n",
    "    # Generate forecast.\n",
    "    historical_df, forecast_df = forecast_bitcoin_prices(historical_data, forecast_days=30)\n",
    "    \n",
    "    if historical_df is not None and forecast_df is not None:\n",
    "        # Display the forecast.\n",
    "        forecast_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20ff58",
   "metadata": {},
   "source": [
    "## Visualizing the Forecast\n",
    "\n",
    "Let's create a visualization of our price forecast with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(historical_df, forecast_df, title=\"Bitcoin Price Forecast\"):\n",
    "    \"\"\"\n",
    "    Plot historical data with forecasted prices\n",
    "    \n",
    "    Args:\n",
    "        historical_df (pd.Series): Historical price data with timestamp index\n",
    "        forecast_df (pd.DataFrame): Forecast data with timestamp index\n",
    "        title (str): Plot title\n",
    "    \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Plotly figure\n",
    "    \"\"\"\n",
    "    # Create figure.\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add historical price.\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=historical_df.index,\n",
    "        y=historical_df,\n",
    "        mode='lines',\n",
    "        name='Historical Price',\n",
    "        line=dict(color='#F2A900', width=2)\n",
    "    ))\n",
    "    \n",
    "    # Add forecast line.\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_df.index,\n",
    "        y=forecast_df['price'],\n",
    "        mode='lines',\n",
    "        name='Forecasted Price',\n",
    "        line=dict(color='red')\n",
    "    ))\n",
    "    \n",
    "    # Add confidence interval.\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_df.index.tolist() + forecast_df.index.tolist()[::-1],\n",
    "        y=forecast_df['upper_bound'].tolist() + forecast_df['lower_bound'].tolist()[::-1],\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(255,0,0,0.2)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='95% Confidence Interval'\n",
    "    ))\n",
    "    \n",
    "    # Update layout.\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Bitcoin Price (USD)',\n",
    "        hovermode='x unified',\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Import enhanced plot_forecast function\n",
    "from utils.plot_forecast import plot_forecast\n",
    "\n",
    "# Plot forecast if available.\n",
    "if 'historical_df' in locals() and 'forecast_df' in locals() and historical_df is not None and forecast_df is not None:\n",
    "    \n",
    "    print(\"[VISUALIZATION] Generating forecast visualization...\")\n",
    "    \n",
    "    # Create forecast plot with enhanced function\n",
    "    fig_forecast = plot_forecast(\n",
    "        historical_df['price'], # Pass just the price series, not the whole dataframe\n",
    "        forecast_df, \n",
    "        title=\"Bitcoin 30-Day Price Forecast with 95% Confidence Interval\"\n",
    "    )\n",
    "    \n",
    "    # Display the plot.\n",
    "    fig_forecast.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159f189",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated a complete workflow for Bitcoin price data analysis using GPU-accelerated cuDF:\n",
    "\n",
    "1. **Data Acquisition**: Fetched historical and real-time Bitcoin price data\n",
    "2. **GPU-Accelerated Processing**: Calculated technical indicators with cuDF\n",
    "3. **Visualization**: Created interactive charts of price trends and indicators\n",
    "4. **Forecasting**: Implemented a simple model to predict future prices\n",
    "\n",
    "This demonstrates how cuDF can significantly enhance the performance of data-intensive financial analysis workflows.\n",
    "\n",
    "For more information, refer to:\n",
    "- The cuDF API documentation in `cudf.API.ipynb` and `cudf.API.md`\n",
    "- Performance benchmarks in `performance_comparison.ipynb` and `performance_comparison.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
