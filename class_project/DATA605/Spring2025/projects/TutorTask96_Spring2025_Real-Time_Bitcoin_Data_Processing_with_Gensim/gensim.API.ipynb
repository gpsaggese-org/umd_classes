{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b45803f",
   "metadata": {},
   "source": [
    "### Gensim Tutorial\n",
    "\n",
    "Gensim is a robust Python library for unsupervised topic modeling and natural language processing. It offers efficient implementations of popular algorithms like Word2Vec, FastText, Doc2Vec, LDA, and LSI. This notebook provides hands-on examples for each of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd732ae4",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c82c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gensim if not already installed\n",
    "\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2319539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sagarmaheshwari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText, Doc2Vec, LdaModel, LsiModel\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbac1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample corpus\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(doc):\n",
    "    return [token for token in simple_preprocess(doc) if token not in stop_words]\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4a9e9",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "Word2Vec generates vector representations of words by training a shallow neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0447d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=processed_docs, vector_size=100, window=5, min_count=1, workers=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b105efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'computer':\n",
      "[-0.00514661 -0.00667657 -0.00777021  0.00832735 -0.00199479 -0.00686069\n",
      " -0.00416312  0.0051635  -0.00288184 -0.00376003  0.00161964 -0.00278592\n",
      " -0.00157794  0.00108014 -0.00298168  0.008512    0.00392145 -0.00995569\n",
      "  0.00624274 -0.00679344  0.00075621  0.00441559 -0.00511017 -0.00212507\n",
      "  0.00809678 -0.00424531 -0.00764362  0.00928519 -0.00217425 -0.00471042\n",
      "  0.00857088  0.00426897  0.00432532  0.00926353 -0.00846707  0.0052542\n",
      "  0.00205502  0.00418248  0.00169106  0.00447188  0.00449154  0.00608854\n",
      " -0.0032179  -0.0045721  -0.00041279  0.00250806 -0.00328215  0.0060547\n",
      "  0.0041642   0.00777352  0.00256294  0.00810639 -0.00137941  0.00808476\n",
      "  0.00370277 -0.00804334 -0.00392963 -0.00247643  0.00487847 -0.00085269\n",
      " -0.00281719  0.00782761  0.00934011 -0.00160275 -0.00516775 -0.00468007\n",
      " -0.0048488  -0.00958754  0.00135457 -0.00422307  0.00253821  0.00562748\n",
      " -0.00405598 -0.00961495  0.00155525 -0.0066844   0.00250963 -0.00377671\n",
      "  0.00707518  0.0006297   0.00355462 -0.00274888 -0.00173281  0.00767256\n",
      "  0.0013947  -0.00584532 -0.0078353   0.00124419  0.00647726  0.00558777\n",
      " -0.00898302  0.00860104  0.00405045  0.00746779  0.00977137 -0.00728253\n",
      " -0.00903232  0.00582981  0.00940664  0.00349814]\n"
     ]
    }
   ],
   "source": [
    "# Access vector for a word\n",
    "vector = w2v_model.wv['computer']\n",
    "print(f\"Vector for 'computer':\\n{vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a88c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'computer':\n",
      "system: 0.21709389984607697\n",
      "unordered: 0.12631958723068237\n",
      "intersection: 0.10369198024272919\n",
      "widths: 0.10257931798696518\n",
      "random: 0.083739273250103\n"
     ]
    }
   ],
   "source": [
    "# Find most similar words\n",
    "similar_words = w2v_model.wv.most_similar('computer', topn=5)\n",
    "print(\"Most similar words to 'computer':\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035912e",
   "metadata": {},
   "source": [
    "### FastText\n",
    "\n",
    "FastText extends Word2Vec by considering subword information, allowing it to generate embeddings for out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c7e6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FastText model\n",
    "ft_model = FastText(sentences=processed_docs, vector_size=100, window=5, min_count=1, workers=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c74824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'computer':\n",
      "[ 2.9880801e-04  3.2837299e-04 -8.7087392e-04  3.4074162e-04\n",
      " -5.0530396e-04 -2.0400675e-03 -1.2366952e-03 -1.9385577e-03\n",
      "  1.3510046e-03 -2.4163353e-03  9.1793487e-04 -1.0294152e-03\n",
      " -7.6270627e-04  7.1173337e-05  1.3854944e-03  5.1190931e-04\n",
      " -2.9630365e-04 -1.1949538e-03 -1.1720804e-03 -6.1215356e-04\n",
      " -6.7950838e-04  3.9473677e-04  1.0080618e-04  8.1050477e-04\n",
      "  5.8251829e-04  7.0226018e-04 -7.3584268e-04 -1.0394261e-03\n",
      " -6.2610256e-04 -2.3708391e-04 -1.1937958e-03 -2.6840135e-04\n",
      "  7.3543075e-04 -7.2244566e-04 -1.2749806e-03  1.2888059e-04\n",
      "  3.8285521e-04 -1.3327518e-03 -2.7399871e-03 -3.0622751e-04\n",
      "  9.2991581e-04 -7.2863739e-04 -1.1310756e-03 -3.2716527e-04\n",
      " -2.0244121e-04 -1.1019036e-04 -6.2306185e-04 -1.6128301e-03\n",
      "  9.9268020e-04  9.7158161e-05  3.6868628e-04 -5.3636177e-04\n",
      "  1.1346547e-03  8.7445206e-04 -1.6418194e-03 -8.5519900e-04\n",
      " -6.4471364e-04  6.2608358e-04  8.3561492e-04 -1.1247990e-03\n",
      "  1.2888766e-03 -3.4181305e-04 -1.1802679e-03 -1.6068361e-03\n",
      "  1.5332046e-03  3.5392033e-05 -2.4253675e-05 -7.2536792e-04\n",
      "  1.7363334e-03  8.9775014e-04  3.2166499e-04 -4.6384402e-04\n",
      " -2.3160656e-03 -1.7167487e-03  4.3756963e-04 -4.0414618e-04\n",
      " -1.0691001e-03 -1.0128192e-03 -1.6432866e-03 -1.0559525e-04\n",
      "  1.0204902e-03 -6.2691973e-04 -1.0854973e-03  8.8420068e-04\n",
      " -1.4565282e-03  6.4191001e-04  4.3915122e-04 -1.2444010e-03\n",
      "  3.5201089e-04 -9.8015659e-04 -9.7780826e-04 -1.9697522e-04\n",
      " -1.9223744e-04 -9.8601065e-04  5.7370804e-04  1.9968008e-03\n",
      "  7.5805765e-05  9.9311350e-04 -1.7060516e-03  1.3537291e-03]\n"
     ]
    }
   ],
   "source": [
    "# Access vector for a word\n",
    "vector = ft_model.wv['computer']\n",
    "print(f\"Vector for 'computer':\\n{vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36534005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'computer':\n",
      "generation: 0.14043159782886505\n",
      "opinion: 0.12851285934448242\n",
      "response: 0.1254628300666809\n",
      "perceived: 0.12263429164886475\n",
      "measurement: 0.1199503019452095\n"
     ]
    }
   ],
   "source": [
    "# Find most similar words\n",
    "similar_words = ft_model.wv.most_similar('computer', topn=5)\n",
    "print(\"Most similar words to 'computer':\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15344bd",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "\n",
    "Doc2Vec represents entire documents as vectors, capturing the semantics of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47cdb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag documents\n",
    "tagged_docs = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(processed_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf0b7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Doc2Vec model\n",
    "d2v_model = Doc2Vec(tagged_docs, vector_size=100, window=5, min_count=1, workers=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c51359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for new document:\n",
      "[ 1.1764626e-03  2.7333130e-03  2.1515836e-04 -3.7031824e-04\n",
      " -1.5070344e-03  3.2378642e-03 -4.5723487e-03 -3.9421222e-05\n",
      "  3.8916387e-03  1.4232891e-03  2.6362306e-03  4.7930083e-03\n",
      "  3.9003030e-03  2.2299709e-03 -3.6341529e-03 -4.8852395e-03\n",
      "  1.8337595e-03 -3.6945071e-03 -3.7225005e-03 -1.6903148e-03\n",
      " -4.7524776e-03 -2.6911485e-04 -1.8954898e-03  4.4092005e-03\n",
      " -1.1342483e-03  1.1098807e-03 -1.9440490e-03  3.4257399e-03\n",
      " -2.4771898e-03 -4.7522308e-03  2.3820894e-03 -7.6019316e-04\n",
      "  1.7676657e-03 -3.8657379e-03 -3.9780149e-04  1.6454047e-03\n",
      "  2.2256067e-03  3.8652827e-03  2.5457109e-03 -2.9814015e-03\n",
      " -3.3781792e-03 -1.3600319e-03 -4.4311825e-03 -3.1819853e-03\n",
      " -2.7437157e-03  3.3696613e-03 -3.2702973e-03 -3.1563635e-03\n",
      "  2.6651809e-03 -3.7297118e-03  8.6977694e-04  1.4308354e-04\n",
      " -3.4440651e-03  1.0450006e-03 -1.2880480e-03  3.6284293e-03\n",
      " -2.8214226e-03 -3.4230915e-03 -1.8694761e-03 -1.7016320e-03\n",
      "  1.8465366e-04 -3.0380900e-03 -4.0114444e-04 -1.9978984e-04\n",
      "  2.3465464e-03 -4.8976657e-03  6.5267639e-04  2.5616973e-03\n",
      "  8.8292011e-04  2.5282829e-04  8.4849272e-04  4.6929033e-03\n",
      "  2.4827891e-03 -2.5490972e-03  3.1090353e-03  1.7051856e-03\n",
      " -1.4234894e-03  3.7596507e-03  2.5058538e-03  1.6837625e-03\n",
      "  9.4066339e-04  1.4836084e-03 -3.3603581e-03  3.7457033e-03\n",
      "  1.0557602e-03  2.1600977e-03 -1.6474457e-03  3.9077974e-03\n",
      "  1.5256375e-03 -2.5735835e-03 -3.9376481e-04  1.3842182e-04\n",
      "  2.2979671e-04 -1.5950765e-03  3.5276993e-03  4.5556980e-03\n",
      " -3.9278967e-03  4.6105138e-03 -1.9986299e-03 -1.2600460e-03]\n"
     ]
    }
   ],
   "source": [
    "# Infer vector for a new document\n",
    "new_doc = preprocess(\"Human computer interaction\")\n",
    "vector = d2v_model.infer_vector(new_doc)\n",
    "print(f\"Vector for new document:\\n{vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d7fcc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents:\n",
      "Document ID 0: 0.08832982927560806\n",
      "Document ID 8: 0.08134177327156067\n",
      "Document ID 3: 0.048103343695402145\n"
     ]
    }
   ],
   "source": [
    "# Find most similar documents\n",
    "similar_docs = d2v_model.dv.most_similar([vector], topn=3)\n",
    "print(\"Most similar documents:\")\n",
    "for doc_id, score in similar_docs:\n",
    "    print(f\"Document ID {doc_id}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16876a4c",
   "metadata": {},
   "source": [
    "### Topic Modeling with LDA\n",
    "\n",
    "LDA identifies topics in a corpus by grouping words that frequently occur together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "818a33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b6521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06389646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics:\n",
      "Topic 0: 0.119*\"system\" + 0.064*\"computer\" + 0.064*\"human\" + 0.063*\"eps\" + 0.063*\"interface\" + 0.063*\"user\" + 0.037*\"survey\" + 0.037*\"testing\" + 0.037*\"opinion\" + 0.037*\"engineering\"\n",
      "Topic 1: 0.057*\"time\" + 0.057*\"response\" + 0.057*\"user\" + 0.056*\"error\" + 0.056*\"perceived\" + 0.056*\"measurement\" + 0.056*\"relation\" + 0.056*\"random\" + 0.056*\"generation\" + 0.056*\"unordered\"\n",
      "Topic 2: 0.123*\"graph\" + 0.087*\"trees\" + 0.086*\"minors\" + 0.049*\"quasi\" + 0.049*\"widths\" + 0.049*\"well\" + 0.049*\"iv\" + 0.049*\"ordering\" + 0.049*\"intersection\" + 0.049*\"paths\"\n"
     ]
    }
   ],
   "source": [
    "# Display topics\n",
    "print(\"LDA Topics:\")\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b4a41",
   "metadata": {},
   "source": [
    "### Topic Modeling with LSI\n",
    "\n",
    "LSI reduces the dimensionality of the term-document matrix using singular value decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c568c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSI model\n",
    "lsi_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "774a7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI Topics:\n",
      "Topic 0: 0.579*\"system\" + 0.376*\"user\" + 0.270*\"eps\" + 0.257*\"response\" + 0.257*\"time\" + 0.230*\"computer\" + 0.224*\"human\" + 0.191*\"interface\" + 0.176*\"survey\" + 0.157*\"opinion\"\n",
      "Topic 1: 0.480*\"graph\" + 0.464*\"trees\" + 0.361*\"minors\" + 0.266*\"quasi\" + 0.266*\"iv\" + 0.266*\"widths\" + 0.266*\"ordering\" + 0.266*\"well\" + 0.119*\"paths\" + 0.119*\"intersection\"\n",
      "Topic 2: 0.359*\"response\" + 0.359*\"time\" + -0.313*\"system\" + 0.301*\"user\" + -0.290*\"human\" + -0.244*\"eps\" + 0.241*\"perceived\" + 0.241*\"measurement\" + 0.241*\"error\" + 0.241*\"relation\"\n"
     ]
    }
   ],
   "source": [
    "# Display topics\n",
    "print(\"LSI Topics:\")\n",
    "for idx, topic in lsi_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e17a69",
   "metadata": {},
   "source": [
    "### Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save models\n",
    "# w2v_model.save(\"word2vec.model\")\n",
    "# ft_model.save(\"fasttext.model\")\n",
    "# d2v_model.save(\"doc2vec.model\")\n",
    "# lda_model.save(\"lda.model\")\n",
    "# lsi_model.save(\"lsi.model\")\n",
    "\n",
    "# # Load models\n",
    "# w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "# ft_model = FastText.load(\"fasttext.model\")\n",
    "# d2v_model = Doc2Vec.load(\"doc2vec.model\")\n",
    "# lda_model = LdaModel.load(\"lda.model\")\n",
    "# lsi_model = LsiModel.load(\"lsi.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3f018",
   "metadata": {},
   "source": [
    "### Coingecko Tutorial\n",
    "\n",
    "CoinGecko provides a free public API to access real-time cryptocurrency data, including current prices, historical trends, and market statistics. This tutorial focuses on using Python to fetch the current price of Bitcoin (BTC) in USD using the `fetch_price` function. The function makes a simple HTTP request to the CoinGecko API and returns the latest Bitcoin price, allowing developers to integrate live crypto data into dashboards, bots, or analytics workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "534430cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103086"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim_utils import fetch_price\n",
    "\n",
    "fetch_price()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
